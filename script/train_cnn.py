"""
CNNè®­ç»ƒè„šæœ¬ - åŸºäº2Då·ç§¯ç½‘ç»œ

æ•°æ®æµç¨‹: (5Ã—5Ã—100)ä¿¡å· â†’ CNN â†’ (10Ã—10)æŸä¼¤å›¾

æ¶æ„è¯´æ˜:
- è¾“å…¥é‡å¡‘: (5, 5, 100) â†’ (100, 5, 5)  # æ—¶é—´ä½œä¸ºé€šé“
- CNNæå–ç‰¹å¾å¹¶ä¸Šé‡‡æ ·åˆ°(10, 10)
- è¾“å‡ºSigmoidæ¿€æ´»ä¿è¯[0,1]æ¦‚ç‡å€¼
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
import json
import argparse  # æ–°å¢

from data.dataset_simple import SimpleUSDataset3D
from data.transform import create_square_cropped_dataset  # æ–°å¢
from nn.cnn import SimpleCNN
from utils.data_utils import prepare_cnn_dataloaders
from utils.train_utils import train_model
from utils.visualization import plot_loss_curves, visualize_prediction


def visualize_cnn_prediction(model, raw_dataset, sample_idx, device, save_path='images/cnn_prediction.png'):
    """
    CNNä¸“ç”¨å¯è§†åŒ–å‡½æ•°
    
    Args:
        model: CNNæ¨¡å‹
        raw_dataset: åŸå§‹æ•°æ®é›†
        sample_idx: æ ·æœ¬ç´¢å¼•
        device: è®¾å¤‡
        save_path: ä¿å­˜è·¯å¾„
    """
    import numpy as np
    import matplotlib.pyplot as plt
    
    model.eval()
    
    # è·å–åŸå§‹æ ·æœ¬
    sig, img_true = raw_dataset[sample_idx]  # (5, 5, 100), (10, 10)
    
    # è½¬æ¢ä¸ºCNNè¾“å…¥æ ¼å¼
    sig_cnn = np.transpose(sig, (2, 0, 1))  # (100, 5, 5)
    sig_tensor = torch.from_numpy(sig_cnn).unsqueeze(0).to(device)  # (1, 100, 5, 5)
    
    # é¢„æµ‹
    with torch.no_grad():
        pred = model(sig_tensor)  # (1, 1, 10, 10)
        img_pred = pred.squeeze().cpu().numpy()  # (10, 10)
    
    # ç»˜å›¾
    fig, axes = plt.subplots(1, 3, figsize=(15, 4))
    
    # çœŸå®æŸä¼¤å›¾
    im0 = axes[0].imshow(img_true, cmap='hot', vmin=0, vmax=1, origin='lower')
    axes[0].set_title('Ground Truth', fontsize=12, fontweight='bold')
    axes[0].set_xlabel('x')
    axes[0].set_ylabel('y')
    plt.colorbar(im0, ax=axes[0], label='Probability')
    
    # é¢„æµ‹æŸä¼¤å›¾
    im1 = axes[1].imshow(img_pred, cmap='hot', vmin=0, vmax=1, origin='lower')
    axes[1].set_title('CNN Prediction', fontsize=12, fontweight='bold')
    axes[1].set_xlabel('x')
    axes[1].set_ylabel('y')
    plt.colorbar(im1, ax=axes[1], label='Probability')
    
    # è¯¯å·®å›¾
    error = np.abs(img_pred - img_true)
    im2 = axes[2].imshow(error, cmap='viridis', vmin=0, vmax=0.5, origin='lower')
    axes[2].set_title(f'Absolute Error (MAE={error.mean():.4f})', fontsize=12, fontweight='bold')
    axes[2].set_xlabel('x')
    axes[2].set_ylabel('y')
    plt.colorbar(im2, ax=axes[2], label='|Error|')
    
    plt.suptitle(f'CNN Prediction (Sample {sample_idx})', fontsize=14, fontweight='bold')
    plt.tight_layout()
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ“ Prediction visualization saved to {save_path}")
    plt.close()


def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    # ==================== è§£æå‘½ä»¤è¡Œå‚æ•° ====================
    parser = argparse.ArgumentParser(description='CNN Training')
    parser.add_argument(
        '--crop',
        action='store_true',
        help='ä½¿ç”¨è£å‰ªæ•°æ®é›†è®­ç»ƒï¼ˆ3Ã—3ç½‘æ ¼ï¼‰'
    )
    parser.add_argument(
        '--crop-position',
        type=str,
        default='boundary',
        choices=['center', 'corner', 'boundary', 'random'],
        help='è£å‰ªä½ç½®'
    )
    args = parser.parse_args()
    
    print("=" * 70)
    print("CNN Training - Simple 2D Convolutional Network")
    if args.crop:
        print(f"ã€è£å‰ªæ¨¡å¼ã€‘Position: {args.crop_position}")
    print("=" * 70)
    
    # ==================== é…ç½®å‚æ•° ====================
    config = {
        # æ•°æ®å‚æ•°ï¼ˆä¸train.pyä¿æŒä¸€è‡´ï¼‰
        'n_samples': 2000,
        'train_ratio': 0.8,
        'nx': 5,
        'ny': 5,
        'sig_len': 100,  # æ—¶é—´æ­¥é•¿
        'img_size': 10,
        # CNNç½‘ç»œå‚æ•°
        'input_channels': 100,  # ä¸sig_lenä¸€è‡´
        'hidden_channels': 64,
        'dropout': 0.15,
        # è®­ç»ƒå‚æ•°ï¼ˆå‚è€ƒtrain.pyï¼‰
        'batch_size': 128,
        'epochs': 100,
        'lr': 5e-4,
        'weight_decay': 1e-4,
        # æ—©åœå’Œå­¦ä¹ ç‡è°ƒåº¦
        'early_stopping': True,
        'patience': 20,
        'use_scheduler': True,
        'scheduler_patience': 5,
        'scheduler_factor': 0.5,
    }
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nâœ“ Device: {device}")
    print(f"âœ“ Training config:")
    print(f"  - Samples: {config['n_samples']}")
    print(f"  - Spatial grid: {config['nx']}Ã—{config['ny']}")
    print(f"  - Time steps: {config['sig_len']}")
    print(f"  - Image size: {config['img_size']}Ã—{config['img_size']}")
    print(f"  - Batch size: {config['batch_size']}")
    print(f"  - Learning rate: {config['lr']}")
    print(f"  - Dropout: {config['dropout']}")
    
    # ==================== åŠ è½½æ•°æ® ====================
    print("\n" + "=" * 70)
    print("Loading Dataset...")
    print("=" * 70)
    
    raw_dataset = SimpleUSDataset3D(
        n_samples=config['n_samples'],
        nx=config['nx'],
        ny=config['ny'],
        sig_len=config['sig_len'],
        img_size=config['img_size'],
        precompute=True
    )
    
    print(f"âœ“ Base dataset loaded: {len(raw_dataset)} samples")
    
    # ã€æ–°å¢ã€‘æ ¹æ®æ˜¯å¦è£å‰ªï¼ŒåŒ…è£…æ•°æ®é›†
    cropper = None
    input_size = config['nx']  # é»˜è®¤5Ã—5
    
    if args.crop:
        print(f"\nğŸ”ª Applying square crop transform...")
        dataset, cropper = create_square_cropped_dataset(
            raw_dataset,
            crop_size=3,
            crop_position=args.crop_position,
            for_cnn=True,  # ä¿æŒç½‘æ ¼æ ¼å¼
            random_seed=42
        )
        input_size = 3  # è£å‰ªå3Ã—3
        print(f"âœ“ Cropped dataset created")
    else:
        dataset = raw_dataset
        print(f"âœ“ Using full dataset (no crop)")
    
    print(f"\nâœ“ Dataset info:")
    print(f"  - Samples: {len(dataset)}")
    print(f"  - Input size: {input_size}Ã—{input_size}Ã—{config['sig_len']}")
    print(f"  - Output size: {config['img_size']}Ã—{config['img_size']}")
    
    # ==================== å‡†å¤‡æ•°æ®åŠ è½½å™¨ ====================
    train_loader, test_loader, train_indices, test_indices = prepare_cnn_dataloaders(
        dataset,
        train_ratio=config['train_ratio'],
        batch_size=config['batch_size']
    )
    
    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    print("\n" + "=" * 70)
    print("Initializing Model...")
    print("=" * 70)
    
    model = SimpleCNN(
        input_channels=config['input_channels'],
        hidden_channels=config['hidden_channels'],
        dropout=config['dropout'],
        input_size=input_size  # ã€æ–°å¢ã€‘ä¼ å…¥è¾“å…¥å°ºå¯¸
    ).to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    model_info = model.get_info()
    print(f"âœ“ Model: {model_info['model_name']}")
    print(f"  - Input: {model_info['input_shape']}")
    print(f"  - Output: {model_info['output_shape']}")
    print(f"  - Parameters: {model_info['total_parameters']:,}")
    
    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )
    
    # ==================== è®­ç»ƒ ====================
    print("\n" + "=" * 70)
    print("Training...")
    print("=" * 70)
    
    os.makedirs('checkpoints', exist_ok=True)
    
    train_losses, test_losses, best_loss = train_model(
        model, train_loader, test_loader,
        criterion, optimizer, device,
        epochs=config['epochs'],
        save_path='checkpoints/best_cnn_model.pth',
        early_stopping=config['early_stopping'],
        patience=config['patience'],
        use_scheduler=config['use_scheduler'],
        scheduler_patience=config['scheduler_patience'],
        scheduler_factor=config['scheduler_factor']
    )
    
    # ==================== ä¿å­˜é…ç½®å’ŒæŒ‡æ ‡ ====================
    print("\nSaving training configuration and metrics...")
    
    # ä¿å­˜é…ç½®
    config['use_crop'] = args.crop
    config['crop_position'] = args.crop_position if args.crop else None
    config['input_size'] = input_size
    
    config_save_path = 'checkpoints/last_cnn_config.json'
    with open(config_save_path, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"âœ“ Config saved to: {config_save_path}")
    
    # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
    metrics = {
        'train_losses': train_losses,
        'test_losses': test_losses,
        'best_test_loss': best_loss,
        'final_train_loss': train_losses[-1],
        'final_test_loss': test_losses[-1],
        'n_epochs_completed': len(train_losses),
    }
    metrics_save_path = 'checkpoints/last_cnn_metrics.pth'
    torch.save(metrics, metrics_save_path)
    print(f"âœ“ Metrics saved to: {metrics_save_path}")
    
    # ==================== å¯è§†åŒ– ====================
    print("\n" + "=" * 70)
    print("Generating Visualizations...")
    print("=" * 70)
    
    os.makedirs('images', exist_ok=True)
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plot_loss_curves(train_losses, test_losses, save_path='images/cnn_loss_curve.png')
    
    # åŠ è½½æœ€ä½³æ¨¡å‹å¹¶é¢„æµ‹
    model.load_state_dict(torch.load('checkpoints/best_cnn_model.pth'))
    visualize_cnn_prediction(model, raw_dataset, test_indices[0], device)
    
    # ==================== æ€»ç»“ ====================
    print("\n" + "=" * 70)
    print("Training Summary")
    print("=" * 70)
    print(f"âœ“ Model: SimpleCNN")
    print(f"âœ“ Input size: {input_size}Ã—{input_size}")
    print(f"âœ“ Epochs: {len(train_losses)}")
    print(f"âœ“ Final train loss: {train_losses[-1]:.6f}")
    print(f"âœ“ Final test loss: {test_losses[-1]:.6f}")
    print(f"âœ“ Best test loss: {best_loss:.6f}")
    if args.crop:
        print(f"âœ“ Training mode: Cropped ({args.crop_position})")
    else:
        print(f"âœ“ Training mode: Full")
    print("=" * 70)
    print("ğŸ‰ CNN Training completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
