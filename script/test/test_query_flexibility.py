"""
æµ‹è¯•DeepONetçš„æŸ¥è¯¢çµæ´»æ€§

å¯¹æ¯”å®éªŒï¼š
1. CNN: åªèƒ½è¾“å‡º5Ã—5
2. DeepONet: å¯ä»¥è¾“å‡º5Ã—5, 10Ã—10, 20Ã—20ç­‰ä»»æ„åˆ†è¾¨ç‡
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import zoom
import json

from data.dataset_simple import SimpleUSDataset3D
from data.transform import create_subgrid_dataset
from nn.deeponet import DeepONet
from nn.cnn import SimpleCNN


def test_deeponet_query(
    model,
    dataset,
    cropper,
    sample_idx: int,
    device,
    query_sizes: list = [5, 10, 20]
):
    """
    æµ‹è¯•DeepONetåœ¨ä¸åŒæŸ¥è¯¢åˆ†è¾¨ç‡ä¸‹çš„é¢„æµ‹
    
    Args:
        model: è®­ç»ƒå¥½çš„DeepONet
        dataset: åŸå§‹10Ã—10æ•°æ®é›†
        cropper: å­ç½‘æ ¼è£å‰ªå™¨
        sample_idx: æµ‹è¯•æ ·æœ¬ç´¢å¼•
        device: è®¾å¤‡
        query_sizes: æŸ¥è¯¢åˆ†è¾¨ç‡åˆ—è¡¨
    
    Returns:
        predictions: {size: pred_array}
    """
    model.eval()
    
    # è·å–åŸå§‹æ•°æ®ï¼ˆ10Ã—10ä¼ æ„Ÿå™¨ç½‘æ ¼ï¼‰
    sig_full, img_target = dataset[sample_idx]
    
    # è£å‰ªåˆ°5Ã—5ç”¨äºBranchè¾“å…¥
    sig_5x5, _ = cropper.crop_signal(sig_full, return_grid=False)
    sig_input = sig_5x5.flatten()
    
    predictions = {}
    
    with torch.no_grad():
        for size in query_sizes:
            print(f"  â†’ Querying {size}Ã—{size} grid...")
            
            # æ„å»ºæŸ¥è¯¢ç½‘æ ¼
            x_grid = np.linspace(0, 1, size)
            y_grid = np.linspace(0, 1, size)
            xv, yv = np.meshgrid(x_grid, y_grid, indexing='xy')
            
            pred_img = np.zeros((size, size))
            
            # é€ç‚¹æŸ¥è¯¢
            for i in range(size):
                for j in range(size):
                    trunk_input = np.array([xv[i, j], yv[i, j]], dtype=np.float32)
                    x_input = np.concatenate([sig_input, trunk_input])
                    x_tensor = torch.from_numpy(x_input).unsqueeze(0).to(device)
                    
                    pred_val = model(x_tensor).cpu().numpy()[0, 0]
                    pred_img[i, j] = pred_val
            
            pred_img = np.clip(pred_img, 0, 1)
            predictions[size] = pred_img
    
    return predictions, img_target


def test_cnn_limitation(
    model,
    dataset,
    cropper,
    sample_idx: int,
    device
):
    """
    æ¼”ç¤ºCNNçš„è¾“å‡ºå°ºå¯¸é™åˆ¶
    
    CNNåªèƒ½è¾“å‡ºè®­ç»ƒæ—¶çš„å›ºå®šå°ºå¯¸ï¼ˆ5Ã—5æˆ–10Ã—10ï¼‰
    """
    model.eval()
    
    # è·å–æ•°æ®
    sig_full, img_target = dataset[sample_idx]
    sig_5x5, _ = cropper.crop_signal(sig_full, return_grid=True)
    
    with torch.no_grad():
        # CNNè¾“å…¥: (1, 100, 5, 5)
        sig_tensor = torch.FloatTensor(sig_5x5).permute(2, 0, 1).unsqueeze(0).to(device)
        pred = model(sig_tensor).squeeze().cpu().numpy()
    
    return pred, img_target


def visualize_comparison(
    deeponet_preds: dict,
    cnn_pred: np.ndarray,
    img_target: np.ndarray,
    save_path: str = 'images/query_flexibility_comparison.png'
):
    """
    å¯è§†åŒ–å¯¹æ¯”ï¼šDeepONetå¤šåˆ†è¾¨ç‡ vs CNNå›ºå®šåˆ†è¾¨ç‡
    """
    fig = plt.figure(figsize=(20, 12))
    
    # ===== ç¬¬ä¸€è¡Œï¼šDeepONetå¤šåˆ†è¾¨ç‡æŸ¥è¯¢ =====
    query_sizes = sorted(deeponet_preds.keys())
    n_sizes = len(query_sizes)
    
    for idx, size in enumerate(query_sizes):
        ax = plt.subplot(3, n_sizes, idx + 1)
        pred = deeponet_preds[size]
        
        im = ax.imshow(pred, cmap='hot', vmin=0, vmax=1, origin='lower',
                      extent=[0, 100, 0, 100])
        ax.set_title(f'DeepONet Query\n{size}Ã—{size} Resolution', 
                    fontweight='bold', fontsize=12)
        ax.set_xlabel('x (mm)')
        ax.set_ylabel('y (mm)')
        plt.colorbar(im, ax=ax, shrink=0.8)
        
        # è®¡ç®—ä¸ç›®æ ‡çš„è¯¯å·®
        if size == 10:
            mae = np.abs(pred - img_target).mean()
            ax.text(0.5, -0.15, f'MAE={mae:.4f}', 
                   transform=ax.transAxes, ha='center', fontsize=10)
    
    # ===== ç¬¬äºŒè¡Œï¼šCNNå›ºå®šè¾“å‡º =====
    ax_cnn = plt.subplot(3, n_sizes, n_sizes + 2)
    im_cnn = ax_cnn.imshow(cnn_pred, cmap='hot', vmin=0, vmax=1, origin='lower',
                          extent=[0, 100, 0, 100])
    ax_cnn.set_title(f'CNN Output\n{cnn_pred.shape[0]}Ã—{cnn_pred.shape[1]} (Fixed)', 
                    fontweight='bold', fontsize=12, color='darkred')
    ax_cnn.set_xlabel('x (mm)')
    ax_cnn.set_ylabel('y (mm)')
    plt.colorbar(im_cnn, ax=ax_cnn, shrink=0.8)
    
    # æ·»åŠ é™åˆ¶è¯´æ˜
    ax_cnn.text(0.5, -0.15, 'âŒ Cannot change output size', 
               transform=ax_cnn.transAxes, ha='center', 
               fontsize=10, color='darkred', fontweight='bold')
    
    # ===== ç¬¬äºŒè¡Œï¼šç›®æ ‡çœŸå€¼ =====
    ax_target = plt.subplot(3, n_sizes, n_sizes + 3)
    im_target = ax_target.imshow(img_target, cmap='hot', vmin=0, vmax=1, origin='lower',
                                extent=[0, 100, 0, 100])
    ax_target.set_title('Ground Truth\n10Ã—10', fontweight='bold', fontsize=12)
    ax_target.set_xlabel('x (mm)')
    ax_target.set_ylabel('y (mm)')
    plt.colorbar(im_target, ax=ax_target, shrink=0.8)
    
    # ===== ç¬¬ä¸‰è¡Œï¼šè¯¯å·®å¯¹æ¯” =====
    for idx, size in enumerate(query_sizes):
        ax = plt.subplot(3, n_sizes, 2*n_sizes + idx + 1)
        pred = deeponet_preds[size]
        
        if size == 10:
            error = np.abs(pred - img_target)
            im_err = ax.imshow(error, cmap='hot', vmin=0, vmax=0.5, origin='lower',
                             extent=[0, 100, 0, 100])
            ax.set_title(f'Error Map ({size}Ã—{size})', fontweight='bold', fontsize=11)
            plt.colorbar(im_err, ax=ax, shrink=0.8)
        else:
            # æ’å€¼åˆ°10Ã—10å†è®¡ç®—è¯¯å·®
            pred_interp = zoom(pred, 10/size, order=1)
            error = np.abs(pred_interp - img_target)
            im_err = ax.imshow(error, cmap='hot', vmin=0, vmax=0.5, origin='lower',
                             extent=[0, 100, 0, 100])
            ax.set_title(f'Error (Interp {size}â†’10)', fontweight='bold', fontsize=11)
            plt.colorbar(im_err, ax=ax, shrink=0.8)
    
    plt.suptitle('DeepONet Query Flexibility: Continuous Operator Learning\n'
                 'Training: 5Ã—5 Input â†’ 5Ã—5 Output | Testing: 5Ã—5 Input â†’ Any Resolution',
                 fontsize=16, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"\nâœ“ Comparison visualization saved to {save_path}")
    plt.close()


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("=" * 70)
    print("Testing Query Flexibility: DeepONet vs CNN")
    print("=" * 70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # ==================== åŠ è½½æ•°æ®é›† ====================
    print("\nğŸ“¦ Loading 10Ã—10 dataset...")
    dataset = SimpleUSDataset3D(
        n_samples=100,  # æµ‹è¯•é›†
        nx=10,
        ny=10,
        sig_len=100,
        img_size=10,
        precompute=True
    )
    
    # åˆ›å»º5Ã—5è£å‰ªå™¨
    _, cropper = create_subgrid_dataset(
        dataset,
        sub_nx=5,
        sub_ny=5,
        position='center',
        for_cnn=False,
        crop_target=False,  # æµ‹è¯•æ—¶ä¸è£å‰ªç›®æ ‡
        random_seed=42
    )
    
    # ==================== åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ ====================
    print("\nğŸ”§ Loading trained models...")
    
    # DeepONet
    config_path = 'checkpoints/last_config.json'
    with open(config_path, 'r') as f:
        deeponet_config = json.load(f)
    
    deeponet = DeepONet(
        branch_dim=deeponet_config['branch_dim'],
        trunk_dim=deeponet_config['trunk_dim'],
        branch_depth=deeponet_config['branch_depth'],
        trunk_depth=deeponet_config['trunk_depth'],
        width=deeponet_config['width'],
        activation='relu',
        initializer='Glorot normal',
        dropout=deeponet_config.get('dropout', 0.0)
    ).to(device)
    deeponet.load_state_dict(torch.load('checkpoints/best_model.pth'))
    print("âœ“ DeepONet loaded")
    
    # CNN
    cnn_config_path = 'checkpoints/last_cnn_config.json'
    with open(cnn_config_path, 'r') as f:
        cnn_config = json.load(f)
    
    cnn = SimpleCNN(
        input_channels=cnn_config['input_channels'],
        hidden_channels=cnn_config['hidden_channels'],
        dropout=cnn_config['dropout'],
        input_size=cnn_config['input_size']
    ).to(device)
    cnn.load_state_dict(torch.load('checkpoints/best_cnn_model.pth'))
    print("âœ“ CNN loaded")
    
    # ==================== æµ‹è¯• ====================
    print("\nğŸ§ª Testing query flexibility...")
    sample_idx = 0
    
    # DeepONetå¤šåˆ†è¾¨ç‡æŸ¥è¯¢
    print("\nğŸ”¹ DeepONet: Querying multiple resolutions...")
    deeponet_preds, img_target = test_deeponet_query(
        deeponet, dataset, cropper,
        sample_idx, device,
        query_sizes=[5, 10, 20, 50]
    )
    
    # CNNå›ºå®šè¾“å‡º
    print("\nğŸ”¹ CNN: Fixed output size...")
    cnn_pred, _ = test_cnn_limitation(
        cnn, dataset, cropper,
        sample_idx, device
    )
    
    # ==================== å¯è§†åŒ–å¯¹æ¯” ====================
    print("\nğŸ“Š Generating comparison visualization...")
    visualize_comparison(
        deeponet_preds,
        cnn_pred,
        img_target,
        save_path='images/query_flexibility_comparison.png'
    )
    
    # ==================== è®¡ç®—æŒ‡æ ‡ ====================
    print("\nğŸ“ˆ Performance Metrics:")
    print("=" * 70)
    
    for size in sorted(deeponet_preds.keys()):
        pred = deeponet_preds[size]
        
        if size == 10:
            mae = np.abs(pred - img_target).mean()
            rmse = np.sqrt(np.mean((pred - img_target)**2))
            print(f"DeepONet {size}Ã—{size}: MAE={mae:.6f}, RMSE={rmse:.6f}")
    
    cnn_mae = np.abs(cnn_pred - img_target).mean()
    cnn_rmse = np.sqrt(np.mean((cnn_pred - img_target)**2))
    print(f"CNN {cnn_pred.shape[0]}Ã—{cnn_pred.shape[1]}: MAE={cnn_mae:.6f}, RMSE={cnn_rmse:.6f}")
    
    print("\n" + "=" * 70)
    print("ğŸ‰ Query flexibility test completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
