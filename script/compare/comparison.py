"""
DeepONet vs CNN æ³›åŒ–æ€§å¯¹æ¯”è„šæœ¬ - MVPç‰ˆæœ¬

å¯¹æ¯”3ä¸ªå…³é”®åœºæ™¯:
1. åŸºçº¿ (5Ã—5Ã—100)
2. ç¨€ç–ä¼ æ„Ÿå™¨ (3Ã—3Ã—100)
3. é«˜åˆ†è¾¨ç‡è¾“å‡º (20Ã—20)
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

import numpy as np
import torch
import time
import json

from data.dataset_simple import SimpleUSDataset3D
from nn.deeponet import DeepONet
from nn.cnn import SimpleCNN
from script.compare.interpolation_utils import interpolate_spatial, interpolate_output_image
from script.compare.visualization_comparison import visualize_scenario_comparison, generate_summary_table


def predict_deeponet(model, sig, output_size, device, train_config=None):
    """
    DeepONeté¢„æµ‹ - ç›´æ¥æŸ¥è¯¢ä»»æ„åˆ†è¾¨ç‡
    
    ã€ä¿®å¤ã€‘å¦‚æœsigç»´åº¦ä¸è®­ç»ƒä¸åŒ¹é…,éœ€è¦æ’å€¼branchè¾“å…¥
    """
    model.eval()
    
    # ã€æ–°å¢ã€‘æ£€æŸ¥branchè¾“å…¥ç»´åº¦,å¿…è¦æ—¶æ’å€¼
    if train_config is not None:
        expected_shape = (train_config['ny'], train_config['nx'], train_config['sig_len'])
        if sig.shape != expected_shape:
            # ç©ºé—´æ’å€¼
            if sig.shape[:2] != (train_config['ny'], train_config['nx']):
                sig = interpolate_spatial(sig, (train_config['ny'], train_config['nx']))
            # æ—¶é—´æ’å€¼(å¦‚æœéœ€è¦)
            if sig.shape[2] != train_config['sig_len']:
                from script.compare.interpolation_utils import interpolate_temporal
                sig = interpolate_temporal(sig, train_config['sig_len'])
    
    branch_vec = sig.flatten()
    branch_batch = torch.from_numpy(branch_vec).unsqueeze(0).to(device)
    
    img_pred = np.zeros((output_size, output_size), dtype=np.float32)
    
    with torch.no_grad():
        for i in range(output_size):
            for j in range(output_size):
                x_norm = j / (output_size - 1) if output_size > 1 else 0.0
                y_norm = i / (output_size - 1) if output_size > 1 else 0.0
                trunk_vec = torch.tensor([[x_norm, y_norm]], dtype=torch.float32).to(device)
                
                x_input = torch.cat([branch_batch, trunk_vec], dim=1)
                pred_val = model(x_input).cpu().numpy()[0, 0]
                img_pred[i, j] = pred_val
    
    return img_pred


def predict_cnn(model, sig, train_config, output_size, device):
    """
    CNNé¢„æµ‹ - éœ€è¦æ’å€¼åˆ°è®­ç»ƒç»´åº¦
    """
    model.eval()
    
    interp_start = time.time()
    
    # 1. è¾“å…¥æ’å€¼
    if sig.shape[:2] != (train_config['ny'], train_config['nx']):
        sig_interp = interpolate_spatial(sig, (train_config['ny'], train_config['nx']))
    else:
        sig_interp = sig
    
    # 2. è½¬æ¢æ ¼å¼
    sig_cnn = np.transpose(sig_interp, (2, 0, 1))
    sig_tensor = torch.from_numpy(sig_cnn).unsqueeze(0).to(device)
    
    interp_time_input = time.time() - interp_start
    
    # 3. CNNé¢„æµ‹
    with torch.no_grad():
        pred = model(sig_tensor)
        pred_np = pred.squeeze().cpu().numpy()
    
    # 4. è¾“å‡ºæ’å€¼
    interp_start = time.time()
    if pred_np.shape[0] != output_size:
        pred_final = interpolate_output_image(pred_np, output_size)
    else:
        pred_final = pred_np
    
    interp_time_output = time.time() - interp_start
    total_interp_time = interp_time_input + interp_time_output
    
    return pred_final, total_interp_time


def compare_scenario(deeponet_model, cnn_model, test_dataset, train_config, 
                     scenario_name, output_size, device):
    """
    åœ¨å•ä¸ªåœºæ™¯ä¸‹å¯¹æ¯”DeepONetå’ŒCNN
    """
    print(f"\n{'='*60}")
    print(f"Scenario: {scenario_name}")
    print(f"{'='*60}")
    
    results = {
        'scenario': scenario_name,
        'deeponet': {'preds': [], 'maes': [], 'times': [], 'interp_times': []},  # ã€ä¿®æ”¹ã€‘æ·»åŠ interp_times
        'cnn': {'preds': [], 'maes': [], 'times': [], 'interp_times': []},
        'true_images': []
    }
    
    n_test = min(5, len(test_dataset))
    
    for i in range(n_test):
        sig, img_true = test_dataset[i]
        
        # DeepONeté¢„æµ‹ ã€ä¿®æ”¹ã€‘æ·»åŠ æ’å€¼æ—¶é—´ç»Ÿè®¡
        start = time.time()
        interp_start = time.time()
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ’å€¼
        expected_shape = (train_config['ny'], train_config['nx'], train_config['sig_len'])
        need_interp = sig.shape != expected_shape
        
        pred_deeponet = predict_deeponet(deeponet_model, sig, output_size, device, train_config)
        
        interp_time_deeponet = time.time() - interp_start if need_interp else 0.0
        time_deeponet = time.time() - start
        
        # è°ƒæ•´çœŸå€¼å°ºå¯¸
        if img_true.shape[0] != output_size:
            img_true_resized = interpolate_output_image(img_true, output_size)
        else:
            img_true_resized = img_true
        
        mae_deeponet = np.mean(np.abs(pred_deeponet - img_true_resized))
        
        # CNNé¢„æµ‹
        start = time.time()
        pred_cnn, interp_time = predict_cnn(cnn_model, sig, train_config, output_size, device)
        time_cnn = time.time() - start
        
        mae_cnn = np.mean(np.abs(pred_cnn - img_true_resized))
        
        # ä¿å­˜ç»“æœ
        results['deeponet']['preds'].append(pred_deeponet)
        results['deeponet']['maes'].append(mae_deeponet)
        results['deeponet']['times'].append(time_deeponet)
        results['deeponet']['interp_times'].append(interp_time_deeponet)  # ã€æ–°å¢ã€‘
        
        results['cnn']['preds'].append(pred_cnn)
        results['cnn']['maes'].append(mae_cnn)
        results['cnn']['times'].append(time_cnn)
        results['cnn']['interp_times'].append(interp_time)
        
        results['true_images'].append(img_true_resized)
    
    # ç»Ÿè®¡
    avg_mae_deeponet = np.mean(results['deeponet']['maes'])
    avg_mae_cnn = np.mean(results['cnn']['maes'])
    avg_time_deeponet = np.mean(results['deeponet']['times'])
    avg_time_cnn = np.mean(results['cnn']['times'])
    avg_interp_time_deeponet = np.mean(results['deeponet']['interp_times'])  # ã€æ–°å¢ã€‘
    avg_interp_time_cnn = np.mean(results['cnn']['interp_times'])
    
    # ã€ä¿®æ”¹ã€‘æ‰“å°ä¿¡æ¯,æ˜¾ç¤ºDeepONetçš„æ’å€¼æ—¶é—´
    if avg_interp_time_deeponet > 0:
        print(f"\n{'DeepONet':12s} | MAE: {avg_mae_deeponet:.6f} | Time: {avg_time_deeponet*1000:.2f}ms (Interp: {avg_interp_time_deeponet*1000:.2f}ms)")
    else:
        print(f"\n{'DeepONet':12s} | MAE: {avg_mae_deeponet:.6f} | Time: {avg_time_deeponet*1000:.2f}ms (No Interp)")
    
    print(f"{'CNN':12s} | MAE: {avg_mae_cnn:.6f} | Time: {avg_time_cnn*1000:.2f}ms (Interp: {avg_interp_time_cnn*1000:.2f}ms)")
    print(f"{'Accuracy Gap':12s} | CNN worse by: {(avg_mae_cnn/avg_mae_deeponet - 1)*100:.1f}%")
    print(f"{'Time Overhead':12s} | CNN slower by: {(avg_time_cnn/avg_time_deeponet - 1)*100:.1f}%")
    
    return results


def main():
    print("="*70)
    print("DeepONet vs CNN Generalization Comparison - MVP")
    print("="*70)
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nâœ“ Device: {device}")
    
    # åŠ è½½æ¨¡å‹
    train_config = {'nx': 5, 'ny': 5, 'sig_len': 100}
    
    deeponet = DeepONet(branch_dim=5*5*100, trunk_dim=2, branch_depth=2, 
                        trunk_depth=3, width=100, dropout=0.15).to(device)
    deeponet.load_state_dict(torch.load('checkpoints/best_model.pth', map_location=device))
    deeponet.eval()
    print("âœ“ DeepONet loaded")
    
    cnn = SimpleCNN(input_channels=100, hidden_channels=64, dropout=0.15).to(device)
    cnn.load_state_dict(torch.load('checkpoints/best_cnn_model.pth', map_location=device))
    cnn.eval()
    print("âœ“ CNN loaded")
    
    # åœºæ™¯1: åŸºçº¿
    dataset_baseline = SimpleUSDataset3D(n_samples=10, nx=5, ny=5, sig_len=100, img_size=10, precompute=True)
    results_baseline = compare_scenario(deeponet, cnn, dataset_baseline, train_config,
                                       'Baseline (5x5x100)', 10, device)
    results_baseline['config_str'] = '5Ã—5Ã—100 â†’ 10Ã—10'
    
    # åœºæ™¯2: ç¨€ç–ä¼ æ„Ÿå™¨
    dataset_sparse = SimpleUSDataset3D(n_samples=10, nx=3, ny=3, sig_len=100, img_size=10, precompute=True)
    results_sparse = compare_scenario(deeponet, cnn, dataset_sparse, train_config,
                                     'Sparse Sensors (3x3x100)', 10, device)
    results_sparse['config_str'] = '3Ã—3Ã—100 â†’ 10Ã—10'
    
    # åœºæ™¯3: é«˜åˆ†è¾¨ç‡è¾“å‡º
    dataset_highres = SimpleUSDataset3D(n_samples=10, nx=5, ny=5, sig_len=100, img_size=50, precompute=True)
    results_highres = compare_scenario(deeponet, cnn, dataset_highres, train_config,
                                      'High-Resolution Output (50x50)', 50, device)
    results_highres['config_str'] = '5Ã—5Ã—100 â†’ 50Ã—50'
    
    # å¯è§†åŒ–
    save_dir = 'images/compare_results'
    visualize_scenario_comparison(results_baseline, save_dir)
    visualize_scenario_comparison(results_sparse, save_dir)
    visualize_scenario_comparison(results_highres, save_dir)
    
    all_results = [results_baseline, results_sparse, results_highres]
    generate_summary_table(all_results, save_dir)
    
    # ä¿å­˜JSON
    summary = {
        'baseline': {'deeponet_mae': float(np.mean(results_baseline['deeponet']['maes'])),
                    'cnn_mae': float(np.mean(results_baseline['cnn']['maes']))},
        'sparse': {'deeponet_mae': float(np.mean(results_sparse['deeponet']['maes'])),
                  'cnn_mae': float(np.mean(results_sparse['cnn']['maes']))},
        'highres': {'deeponet_mae': float(np.mean(results_highres['deeponet']['maes'])),
                   'cnn_mae': float(np.mean(results_highres['cnn']['maes']))}
    }
    with open(os.path.join(save_dir, 'comparison_summary.json'), 'w') as f:
        json.dump(summary, f, indent=2)
    
    print("\n" + "="*70)
    print("âœ… Comparison completed!")
    print(f"ğŸ“ Results: {os.path.abspath(save_dir)}")
    print("="*70)


if __name__ == "__main__":
    main()
