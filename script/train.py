"""
DeepONetè®­ç»ƒè„šæœ¬ - ç²¾ç®€ç‰ˆ

æ•°æ®æµç¨‹: 5Ã—5Ã—50ä¿¡å· â†’ DeepONet â†’ 10Ã—10æŸä¼¤å›¾

ã€æ–°å¢ã€‘æ”¯æŒè£å‰ªæ•°æ®é›†è®­ç»ƒï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
import json
import argparse
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import zoom

from data.dataset_simple import SimpleUSDataset3D
from data.transform import create_cropped_dataset, create_square_cropped_dataset  # ä¿®æ”¹å¯¼å…¥
from nn.deeponet import DeepONet
from utils.data_utils import prepare_dataloaders
from utils.train_utils import train_model
from utils.visualization import plot_loss_curves, visualize_prediction


def visualize_cropped_dataset_deeponet(raw_dataset, cropper, sample_idx=0, save_path='images/deeponet_cropped_data.png'):
    """
    å¯è§†åŒ–DeepONetä½¿ç”¨çš„è£å‰ªæ•°æ®é›†
    
    å±•ç¤ºå†…å®¹ï¼š
    1. åŸå§‹ 5Ã—5 ç©ºé—´åˆ†å¸ƒï¼ˆæŸæ—¶åˆ»ï¼‰
    2. è£å‰ªæ©ç ï¼ˆå“ªäº›ä¼ æ„Ÿå™¨è¢«ä¿ç•™ï¼‰
    3. è£å‰ªåä¿¡å·çš„æ—¶åŸŸæ³¢å½¢ï¼ˆflattenæˆä¸€ç»´ï¼‰
    4. ç›®æ ‡æŸä¼¤å›¾ï¼ˆä¸å˜ï¼‰
    
    Args:
        raw_dataset: åŸå§‹æ•°æ®é›†
        cropper: è£å‰ªå™¨ï¼ˆSquareCropperï¼‰
        sample_idx: æ ·æœ¬ç´¢å¼•
        save_path: ä¿å­˜è·¯å¾„
    """
    print(f"\nğŸ“Š Visualizing cropped dataset for DeepONet...")
    
    # è·å–åŸå§‹æ ·æœ¬
    sig_full, img_target = raw_dataset[sample_idx]  # (5, 5, 100), (10, 10)
    
    # è£å‰ªä¿¡å·ï¼ˆDeepONetéœ€è¦flattenï¼‰
    sig_cropped, kept_indices = cropper.crop_signal(sig_full, return_grid=False)
    # sig_cropped: (9, 100)
    
    # å¯è§†åŒ–æ©ç 
    mask = cropper.visualize_crop_pattern()  # (5, 5)
    
    # åˆ›å»ºå›¾å½¢
    fig = plt.figure(figsize=(20, 10))
    
    # ===== 1. åŸå§‹ 5Ã—5 ç©ºé—´åˆ†å¸ƒï¼ˆæŸæ—¶åˆ»ï¼‰=====
    ax1 = plt.subplot(2, 4, 1)
    time_idx = 20
    spatial_full = sig_full[:, :, time_idx]
    spatial_full_interp = zoom(spatial_full, 8, order=1)
    
    im1 = ax1.imshow(spatial_full_interp, cmap='seismic',
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal', vmin=-1, vmax=1)
    ax1.set_title('â‘  Full Signal (5Ã—5)\nat t=20Î¼s', fontsize=12, fontweight='bold')
    ax1.set_xlabel('x (mm)')
    ax1.set_ylabel('y (mm)')
    plt.colorbar(im1, ax=ax1, shrink=0.8)
    
    # æ ‡è®°æ‰€æœ‰ä¼ æ„Ÿå™¨
    x_pos = np.linspace(0, 100, 5)
    y_pos = np.linspace(0, 100, 5)
    xv, yv = np.meshgrid(x_pos, y_pos)
    ax1.plot(xv.flatten(), yv.flatten(), 'ko', markersize=8, alpha=0.6)
    
    # ===== 2. è£å‰ªæ©ç  =====
    ax2 = plt.subplot(2, 4, 2)
    im2 = ax2.imshow(mask, cmap='RdYlGn', vmin=0, vmax=1, origin='lower')
    ax2.set_title(f'â‘¡ Crop Mask\n({cropper.crop_position} mode)', fontsize=12, fontweight='bold')
    
    for y in range(5):
        for x in range(5):
            if mask[y, x] == 1:
                ax2.plot(x, y, 'go', markersize=20)
                ax2.text(x, y, 'âœ“', ha='center', va='center',
                        color='white', fontweight='bold', fontsize=14)
            else:
                ax2.plot(x, y, 'rx', markersize=15, markeredgewidth=3)
                ax2.text(x, y, 'âœ—', ha='center', va='center',
                        color='darkred', fontweight='bold', fontsize=14)
    
    ax2.set_xticks(range(5))
    ax2.set_yticks(range(5))
    ax2.set_xlabel('x index')
    ax2.set_ylabel('y index')
    ax2.grid(True, alpha=0.3, linestyle='--')
    plt.colorbar(im2, ax=ax2, shrink=0.8, label='Kept (1) / Removed (0)')
    
    # ===== 3. è£å‰ªåç©ºé—´åˆ†å¸ƒï¼ˆé‡æ„åˆ°3Ã—3ï¼‰=====
    ax3 = plt.subplot(2, 4, 3)
    # å°†è£å‰ªåçš„ä¿¡å·é‡æ„å›3Ã—3ç½‘æ ¼
    sig_cropped_grid = sig_cropped.reshape(3, 3, 100)
    spatial_cropped = sig_cropped_grid[:, :, time_idx]
    spatial_cropped_interp = zoom(spatial_cropped, 8, order=1)
    
    im3 = ax3.imshow(spatial_cropped_interp, cmap='seismic',
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal', vmin=-1, vmax=1)
    ax3.set_title('â‘¢ Cropped Signal (3Ã—3)\nat t=20Î¼s', fontsize=12, fontweight='bold')
    ax3.set_xlabel('x (mm)')
    ax3.set_ylabel('y (mm)')
    plt.colorbar(im3, ax=ax3, shrink=0.8)
    
    # æ ‡è®°ä¿ç•™çš„ä¼ æ„Ÿå™¨
    x_kept = np.linspace(0, 100, 3)
    y_kept = np.linspace(0, 100, 3)
    xv_kept, yv_kept = np.meshgrid(x_kept, y_kept)
    ax3.plot(xv_kept.flatten(), yv_kept.flatten(), 'go', markersize=8)
    
    # ===== 4. ç›®æ ‡æŸä¼¤å›¾ï¼ˆä¸å˜ï¼‰=====
    ax4 = plt.subplot(2, 4, 4)
    im4 = ax4.imshow(img_target, cmap='hot', vmin=0, vmax=1,
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal')
    ax4.set_title('â‘£ Target (10Ã—10)\n(Unchanged)', fontsize=12, fontweight='bold')
    ax4.set_xlabel('x (mm)')
    ax4.set_ylabel('y (mm)')
    plt.colorbar(im4, ax=ax4, shrink=0.8, label='Probability')
    
    # ===== 5. å®Œæ•´ä¿¡å·æ—¶åŸŸæ³¢å½¢ï¼ˆé€‰3ä¸ªç‚¹ï¼‰=====
    ax5 = plt.subplot(2, 4, 5)
    t_vec = np.linspace(0, 100, 100)
    
    # é€‰æ‹©3ä¸ªä¿ç•™ç‚¹çš„æ³¢å½¢
    for i in range(min(3, len(kept_indices))):
        y_idx, x_idx = kept_indices[i]
        sig_point = sig_full[y_idx, x_idx, :]
        ax5.plot(t_vec, sig_point, linewidth=1.2, 
                label=f'Kept point ({x_idx},{y_idx})', alpha=0.8)
    
    ax5.set_xlabel('Time (Î¼s)', fontsize=10)
    ax5.set_ylabel('Amplitude', fontsize=10)
    ax5.set_title('â‘¤ Time Signals (Kept Points)', fontsize=12, fontweight='bold')
    ax5.grid(True, alpha=0.3)
    ax5.legend(fontsize=9)
    ax5.axhline(0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)
    
    # ===== 6. è¢«ç§»é™¤ç‚¹çš„æ³¢å½¢ï¼ˆå¯¹æ¯”ï¼‰=====
    ax6 = plt.subplot(2, 4, 6)
    
    # æ‰¾å‡ºè¢«ç§»é™¤çš„ç‚¹
    all_points = [(y, x) for y in range(5) for x in range(5)]
    removed_indices = [pt for pt in all_points if pt not in kept_indices]
    
    for i in range(min(3, len(removed_indices))):
        y_idx, x_idx = removed_indices[i]
        sig_point = sig_full[y_idx, x_idx, :]
        ax6.plot(t_vec, sig_point, linewidth=1.2, linestyle='--',
                label=f'Removed ({x_idx},{y_idx})', alpha=0.7)
    
    ax6.set_xlabel('Time (Î¼s)', fontsize=10)
    ax6.set_ylabel('Amplitude', fontsize=10)
    ax6.set_title('â‘¥ Time Signals (Removed Points)', fontsize=12, fontweight='bold')
    ax6.grid(True, alpha=0.3)
    ax6.legend(fontsize=9)
    ax6.axhline(0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)
    
    # ===== 7. DeepONetè¾“å…¥ç»´åº¦è¯´æ˜ =====
    ax7 = plt.subplot(2, 4, 7)
    ax7.axis('off')
    
    text_info = f"""
    ğŸ“Š DeepONet Input Transformation
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ”µ Original Signal:
       â€¢ Shape: (5, 5, 100)
       â€¢ Total: 2500 time samples
       â€¢ Branch input: 2500 dims
    
    âœ‚ï¸ After Cropping:
       â€¢ Shape: (3, 3, 100) â†’ flatten
       â€¢ Total: 900 time samples
       â€¢ Branch input: 900 dims
    
    ğŸ“‰ Dimension Reduction:
       2500 â†’ 900 (36% retained)
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ¯ Target (Unchanged):
       â€¢ Shape: (10, 10)
       â€¢ Total: 100 output points
    
    ğŸ’¡ Key Insight:
       DeepONet must infer full damage
       from incomplete observations!
    """
    
    ax7.text(0.05, 0.5, text_info, fontsize=10, family='monospace',
            verticalalignment='center', transform=ax7.transAxes)
    
    # ===== 8. ä¿¡å·èƒ½é‡åˆ†å¸ƒå¯¹æ¯” =====
    ax8 = plt.subplot(2, 4, 8)
    
    # è®¡ç®—æ¯ä¸ªç‚¹çš„RMSèƒ½é‡
    rms_full = np.sqrt(np.mean(sig_full**2, axis=2))  # (5, 5)
    rms_cropped = np.sqrt(np.mean(sig_cropped_grid**2, axis=2))  # (3, 3)
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾å¯¹æ¯”
    rms_full_interp = zoom(rms_full, 4, order=1)
    im8 = ax8.imshow(rms_full_interp, cmap='viridis',
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal')
    
    # å åŠ è£å‰ªåŒºåŸŸæ¡†
    if cropper.crop_position == 'center':
        # ä¸­å¿ƒ3Ã—3å¯¹åº”çš„ç‰©ç†ä½ç½®
        rect_x = [20, 80, 80, 20, 20]
        rect_y = [20, 20, 80, 80, 20]
        ax8.plot(rect_x, rect_y, 'r-', linewidth=3, label='Kept region')
    
    ax8.set_title('â‘§ RMS Energy Distribution\n(Full grid)', fontsize=12, fontweight='bold')
    ax8.set_xlabel('x (mm)')
    ax8.set_ylabel('y (mm)')
    plt.colorbar(im8, ax=ax8, shrink=0.8, label='RMS Energy')
    ax8.legend(fontsize=9)
    
    plt.suptitle(f'DeepONet Cropped Dataset Visualization (Sample {sample_idx})\n'
                 f'Crop Mode: {cropper.crop_position} | Kept: 9/25 sensors (36%)',
                 fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ“ Visualization saved to {save_path}")
    plt.close()


def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    # ==================== è§£æå‘½ä»¤è¡Œå‚æ•° ====================
    parser = argparse.ArgumentParser(description='DeepONet Training')
    parser.add_argument(
        '--crop',
        action='store_true',
        help='ä½¿ç”¨è£å‰ªæ•°æ®é›†è®­ç»ƒ'
    )
    parser.add_argument(
        '--crop-mode',
        type=str,
        default='square',
        choices=['boundary', 'random', 'square'],
        help='è£å‰ªæ¨¡å¼ï¼šboundary-è¾¹ç•Œç‚¹, random-éšæœºç‚¹, square-æ­£æ–¹å½¢è£å‰ª'
    )
    parser.add_argument(
        '--crop-position',
        type=str,
        default='center',  # ã€ä¿®æ”¹ã€‘é»˜è®¤centerï¼ˆä¿ç•™ä¸­å¿ƒ3Ã—3ï¼‰
        choices=['center', 'corner', 'boundary', 'random'],
        help='squareæ¨¡å¼ä¸‹çš„è£å‰ªä½ç½®ï¼šcenter-ä¸­å¿ƒ3Ã—3, boundary-è¾¹ç•Œåˆ†æ•£'
    )
    parser.add_argument(
        '--n-keep',
        type=int,
        default=None,
        help='randomæ¨¡å¼ä¸‹ä¿ç•™çš„ä¼ æ„Ÿå™¨æ•°é‡'
    )
    args = parser.parse_args()
    
    print("=" * 70)
    print("DeepONet Training - Simplified")
    if args.crop:
        print(f"ã€è£å‰ªæ¨¡å¼ã€‘Mode: {args.crop_mode}")
    print("=" * 70)
    
    # ==================== é…ç½®å‚æ•° ====================
    config = {
        # æ•°æ®å‚æ•°
        'n_samples': 2000,
        'train_ratio': 0.8,
        'nx': 5,
        'ny': 5,
        'sig_len': 100,
        # ã€å…³é”®ã€‘branch_dim å°†æ ¹æ®æ˜¯å¦è£å‰ªè‡ªåŠ¨è°ƒæ•´
        'branch_dim': None,  # ç¨åè®¾ç½®
        'trunk_dim': 2,
        'branch_depth': 2,
        'trunk_depth': 3,
        'width': 100,
        'dropout': 0.15,
        # è®­ç»ƒå‚æ•°
        'batch_size': 128,
        'epochs': 100,
        'lr': 5e-4,
        'weight_decay': 1e-4,
        # æ—©åœå‚æ•°
        'early_stopping': True,
        'patience': 20,
        # å­¦ä¹ ç‡è°ƒåº¦
        'use_scheduler': True,
        'scheduler_patience': 5,
        'scheduler_factor': 0.5,
        # ã€æ–°å¢ã€‘è£å‰ªå‚æ•°
        'use_crop': args.crop,
        'crop_mode': args.crop_mode,
        'n_keep': args.n_keep,
    }
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nâœ“ Device: {device}")
    
    # ==================== åŠ è½½æ•°æ® ====================
    print("\n" + "=" * 70)
    print("Loading Dataset...")
    print("=" * 70)
    
    # åˆ›å»ºåŸå§‹æ•°æ®é›†
    raw_dataset = SimpleUSDataset3D(
        n_samples=config['n_samples'],
        nx=config['nx'],
        ny=config['ny'],
        sig_len=config['sig_len'],
        img_size=10,
        precompute=True
    )
    
    print(f"âœ“ Base dataset loaded: {len(raw_dataset)} samples")
    
    # ã€æ–°å¢ã€‘æ ¹æ®æ˜¯å¦è£å‰ªï¼ŒåŒ…è£…æ•°æ®é›†
    cropper = None
    if config['use_crop']:
        print(f"\nğŸ”ª Applying crop transform...")
        
        if config['crop_mode'] == 'square':
            # ã€æ–°å¢ã€‘æ­£æ–¹å½¢è£å‰ªï¼ˆ3Ã—3ï¼‰
            dataset, cropper = create_square_cropped_dataset(
                raw_dataset,
                crop_size=3,
                crop_position=args.crop_position,
                for_cnn=False,  # DeepONetéœ€è¦flatten
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
            
            # ã€æ–°å¢ã€‘å¯è§†åŒ–è£å‰ªæ•°æ®é›†
            print("\nğŸ¨ Generating cropped dataset visualization...")
            visualize_cropped_dataset_deeponet(
                raw_dataset, 
                cropper, 
                sample_idx=0,
                save_path='images/deeponet_cropped_data_check.png'
            )
        else:
            # åŸæœ‰çš„boundary/randomæ¨¡å¼
            dataset, cropper = create_cropped_dataset(
                raw_dataset,
                crop_mode=config['crop_mode'],
                n_keep=config['n_keep'],
                random_per_sample=True,
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
        
        print(f"âœ“ Cropped dataset created")
    else:
        dataset = raw_dataset
        config['branch_dim'] = config['nx'] * config['ny'] * config['sig_len']
        print(f"âœ“ Using full dataset (no crop)")
    
    print(f"\nâœ“ Training config:")
    print(f"  - Samples: {config['n_samples']}")
    print(f"  - Spatial grid: {config['nx']}Ã—{config['ny']}")
    print(f"  - Time steps: {config['sig_len']}")
    print(f"  - Branch dim: {config['branch_dim']}")
    if config['use_crop']:
        print(f"  - Crop mode: {config['crop_mode']}")
    print(f"  - Batch size: {config['batch_size']}")
    print(f"  - Learning rate: {config['lr']}")
    
    # ==================== å‡†å¤‡æ•°æ®åŠ è½½å™¨ ====================
    train_loader, test_loader, train_indices, test_indices = prepare_dataloaders(
        dataset,
        train_ratio=config['train_ratio'],
        batch_size=config['batch_size']
    )
    
    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    print("\n" + "=" * 70)
    print("Initializing Model...")
    print("=" * 70)
    
    model = DeepONet(
        branch_dim=config['branch_dim'],
        trunk_dim=config['trunk_dim'],
        branch_depth=config['branch_depth'],
        trunk_depth=config['trunk_depth'],
        width=config['width'],
        activation='relu',
        initializer='Glorot normal',
        dropout=config.get('dropout', 0.0)
    ).to(device)
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )
    
    n_params = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Model initialized: {n_params:,} parameters")
    
    # ==================== è®­ç»ƒ ====================
    print("\n" + "=" * 70)
    print("Training...")
    print("=" * 70)
    
    os.makedirs('checkpoints', exist_ok=True)
    
    train_losses, test_losses, best_loss = train_model(
        model, train_loader, test_loader,
        criterion, optimizer, device,
        epochs=config['epochs'],
        save_path='checkpoints/best_model.pth',
        early_stopping=config['early_stopping'],
        patience=config['patience'],
        use_scheduler=config['use_scheduler'],
        scheduler_patience=config['scheduler_patience'],
        scheduler_factor=config['scheduler_factor']
    )
    
    # ==================== ä¿å­˜é…ç½®å’ŒæŒ‡æ ‡ ====================
    print("\nSaving training configuration and metrics...")
    
    config_save_path = 'checkpoints/last_config.json'
    with open(config_save_path, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"âœ“ Config saved to: {config_save_path}")
    
    metrics = {
        'train_losses': train_losses,
        'test_losses': test_losses,
        'best_test_loss': best_loss,
        'final_train_loss': train_losses[-1],
        'final_test_loss': test_losses[-1],
        'n_epochs_completed': len(train_losses),
    }
    metrics_save_path = 'checkpoints/last_metrics.pth'
    torch.save(metrics, metrics_save_path)
    print(f"âœ“ Metrics saved to: {metrics_save_path}")
    
    # ==================== å¯è§†åŒ– ====================
    print("\n" + "=" * 70)
    print("Generating Visualizations...")
    print("=" * 70)
    
    os.makedirs('images', exist_ok=True)
    
    plot_loss_curves(train_losses, test_losses)
    
    # ã€ä¿®å¤ã€‘åŠ è½½æœ€ä½³æ¨¡å‹å¹¶é¢„æµ‹ï¼Œä¼ é€’cropper
    model.load_state_dict(torch.load('checkpoints/best_model.pth'))
    visualize_prediction(
        model, 
        raw_dataset, 
        test_indices[0], 
        device,
        cropper=cropper
    )
    
    # ã€æ–°å¢ã€‘å¦‚æœä½¿ç”¨äº†è£å‰ªï¼Œå†æ¬¡å¯è§†åŒ–è£å‰ªæ•°æ®é›†ï¼ˆä½¿ç”¨æµ‹è¯•æ ·æœ¬ï¼‰
    if config['use_crop'] and cropper is not None:
        os.makedirs('images/dataset_check', exist_ok=True)
        print("\nğŸ¨ Generating final cropped dataset visualization (test sample)...")
        visualize_cropped_dataset_deeponet(
            raw_dataset,
            cropper,
            sample_idx=test_indices[0],
            save_path='images/dataset_check/deeponet_cropped_test_sample.png'
        )
    
    # ==================== æ€»ç»“ ====================
    print("\n" + "=" * 70)
    print("Training Summary")
    print("=" * 70)
    print(f"âœ“ Epochs: {config['epochs']}")
    print(f"âœ“ Final train loss: {train_losses[-1]:.6f}")
    print(f"âœ“ Final test loss: {test_losses[-1]:.6f}")
    print(f"âœ“ Best test loss: {best_loss:.6f}")
    if config['use_crop']:
        print(f"âœ“ Training mode: Cropped ({config['crop_mode']})")
    else:
        print(f"âœ“ Training mode: Full")
    print("=" * 70)
    print("ğŸ‰ Training completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
