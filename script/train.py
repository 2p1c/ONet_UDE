"""
DeepONetè®­ç»ƒè„šæœ¬ - ç²¾ç®€ç‰ˆ

æ•°æ®æµç¨‹: 5Ã—5Ã—50ä¿¡å· â†’ DeepONet â†’ 10Ã—10æŸä¼¤å›¾

ã€æ–°å¢ã€‘æ”¯æŒè£å‰ªæ•°æ®é›†è®­ç»ƒï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
import json
import argparse  # æ–°å¢

from data.dataset_simple import SimpleUSDataset3D
from data.transform import create_cropped_dataset, create_square_cropped_dataset  # ä¿®æ”¹å¯¼å…¥
from nn.deeponet import DeepONet
from utils.data_utils import prepare_dataloaders
from utils.train_utils import train_model
from utils.visualization import plot_loss_curves, visualize_prediction


def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    # ==================== è§£æå‘½ä»¤è¡Œå‚æ•° ====================
    parser = argparse.ArgumentParser(description='DeepONet Training')
    parser.add_argument(
        '--crop',
        action='store_true',
        help='ä½¿ç”¨è£å‰ªæ•°æ®é›†è®­ç»ƒ'
    )
    parser.add_argument(
        '--crop-mode',
        type=str,
        default='square',  # ã€ä¿®æ”¹ã€‘é»˜è®¤squareæ¨¡å¼
        choices=['boundary', 'random', 'square'],  # ã€æ–°å¢ã€‘squareé€‰é¡¹
        help='è£å‰ªæ¨¡å¼ï¼šboundary-è¾¹ç•Œç‚¹, random-éšæœºç‚¹, square-æ­£æ–¹å½¢è£å‰ª'
    )
    parser.add_argument(
        '--crop-position',
        type=str,
        default='boundary',
        choices=['center', 'corner', 'boundary', 'random'],
        help='squareæ¨¡å¼ä¸‹çš„è£å‰ªä½ç½®'
    )
    parser.add_argument(
        '--n-keep',
        type=int,
        default=None,
        help='randomæ¨¡å¼ä¸‹ä¿ç•™çš„ä¼ æ„Ÿå™¨æ•°é‡'
    )
    args = parser.parse_args()
    
    print("=" * 70)
    print("DeepONet Training - Simplified")
    if args.crop:
        print(f"ã€è£å‰ªæ¨¡å¼ã€‘Mode: {args.crop_mode}")
    print("=" * 70)
    
    # ==================== é…ç½®å‚æ•° ====================
    config = {
        # æ•°æ®å‚æ•°
        'n_samples': 2000,
        'train_ratio': 0.8,
        'nx': 5,
        'ny': 5,
        'sig_len': 100,
        # ã€å…³é”®ã€‘branch_dim å°†æ ¹æ®æ˜¯å¦è£å‰ªè‡ªåŠ¨è°ƒæ•´
        'branch_dim': None,  # ç¨åè®¾ç½®
        'trunk_dim': 2,
        'branch_depth': 2,
        'trunk_depth': 3,
        'width': 100,
        'dropout': 0.15,
        # è®­ç»ƒå‚æ•°
        'batch_size': 128,
        'epochs': 100,
        'lr': 5e-4,
        'weight_decay': 1e-4,
        # æ—©åœå‚æ•°
        'early_stopping': True,
        'patience': 20,
        # å­¦ä¹ ç‡è°ƒåº¦
        'use_scheduler': True,
        'scheduler_patience': 5,
        'scheduler_factor': 0.5,
        # ã€æ–°å¢ã€‘è£å‰ªå‚æ•°
        'use_crop': args.crop,
        'crop_mode': args.crop_mode,
        'n_keep': args.n_keep,
    }
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nâœ“ Device: {device}")
    
    # ==================== åŠ è½½æ•°æ® ====================
    print("\n" + "=" * 70)
    print("Loading Dataset...")
    print("=" * 70)
    
    # åˆ›å»ºåŸå§‹æ•°æ®é›†
    raw_dataset = SimpleUSDataset3D(
        n_samples=config['n_samples'],
        nx=config['nx'],
        ny=config['ny'],
        sig_len=config['sig_len'],
        img_size=10,
        precompute=True
    )
    
    print(f"âœ“ Base dataset loaded: {len(raw_dataset)} samples")
    
    # ã€æ–°å¢ã€‘æ ¹æ®æ˜¯å¦è£å‰ªï¼ŒåŒ…è£…æ•°æ®é›†
    cropper = None
    if config['use_crop']:
        print(f"\nğŸ”ª Applying crop transform...")
        
        if config['crop_mode'] == 'square':
            # ã€æ–°å¢ã€‘æ­£æ–¹å½¢è£å‰ªï¼ˆ3Ã—3ï¼‰
            dataset, cropper = create_square_cropped_dataset(
                raw_dataset,
                crop_size=3,
                crop_position=args.crop_position,
                for_cnn=False,  # DeepONetéœ€è¦flatten
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
        else:
            # åŸæœ‰çš„boundary/randomæ¨¡å¼
            dataset, cropper = create_cropped_dataset(
                raw_dataset,
                crop_mode=config['crop_mode'],
                n_keep=config['n_keep'],
                random_per_sample=True,
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
        
        print(f"âœ“ Cropped dataset created")
    else:
        dataset = raw_dataset
        config['branch_dim'] = config['nx'] * config['ny'] * config['sig_len']
        print(f"âœ“ Using full dataset (no crop)")
    
    print(f"\nâœ“ Training config:")
    print(f"  - Samples: {config['n_samples']}")
    print(f"  - Spatial grid: {config['nx']}Ã—{config['ny']}")
    print(f"  - Time steps: {config['sig_len']}")
    print(f"  - Branch dim: {config['branch_dim']}")
    if config['use_crop']:
        print(f"  - Crop mode: {config['crop_mode']}")
    print(f"  - Batch size: {config['batch_size']}")
    print(f"  - Learning rate: {config['lr']}")
    
    # ==================== å‡†å¤‡æ•°æ®åŠ è½½å™¨ ====================
    train_loader, test_loader, train_indices, test_indices = prepare_dataloaders(
        dataset,
        train_ratio=config['train_ratio'],
        batch_size=config['batch_size']
    )
    
    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    print("\n" + "=" * 70)
    print("Initializing Model...")
    print("=" * 70)
    
    model = DeepONet(
        branch_dim=config['branch_dim'],
        trunk_dim=config['trunk_dim'],
        branch_depth=config['branch_depth'],
        trunk_depth=config['trunk_depth'],
        width=config['width'],
        activation='relu',
        initializer='Glorot normal',
        dropout=config.get('dropout', 0.0)
    ).to(device)
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )
    
    n_params = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Model initialized: {n_params:,} parameters")
    
    # ==================== è®­ç»ƒ ====================
    print("\n" + "=" * 70)
    print("Training...")
    print("=" * 70)
    
    os.makedirs('checkpoints', exist_ok=True)
    
    train_losses, test_losses, best_loss = train_model(
        model, train_loader, test_loader,
        criterion, optimizer, device,
        epochs=config['epochs'],
        save_path='checkpoints/best_model.pth',
        early_stopping=config['early_stopping'],
        patience=config['patience'],
        use_scheduler=config['use_scheduler'],
        scheduler_patience=config['scheduler_patience'],
        scheduler_factor=config['scheduler_factor']
    )
    
    # ==================== ä¿å­˜é…ç½®å’ŒæŒ‡æ ‡ ====================
    print("\nSaving training configuration and metrics...")
    
    config_save_path = 'checkpoints/last_config.json'
    with open(config_save_path, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"âœ“ Config saved to: {config_save_path}")
    
    metrics = {
        'train_losses': train_losses,
        'test_losses': test_losses,
        'best_test_loss': best_loss,
        'final_train_loss': train_losses[-1],
        'final_test_loss': test_losses[-1],
        'n_epochs_completed': len(train_losses),
    }
    metrics_save_path = 'checkpoints/last_metrics.pth'
    torch.save(metrics, metrics_save_path)
    print(f"âœ“ Metrics saved to: {metrics_save_path}")
    
    # ==================== å¯è§†åŒ– ====================
    print("\n" + "=" * 70)
    print("Generating Visualizations...")
    print("=" * 70)
    
    os.makedirs('images', exist_ok=True)
    
    plot_loss_curves(train_losses, test_losses)
    
    # ã€ä¿®å¤ã€‘åŠ è½½æœ€ä½³æ¨¡å‹å¹¶é¢„æµ‹ï¼Œä¼ é€’cropper
    model.load_state_dict(torch.load('checkpoints/best_model.pth'))
    visualize_prediction(
        model, 
        raw_dataset, 
        test_indices[0], 
        device,
        cropper=cropper  # ã€æ–°å¢ã€‘ä¼ é€’è£å‰ªå™¨
    )
    
    # ==================== æ€»ç»“ ====================
    print("\n" + "=" * 70)
    print("Training Summary")
    print("=" * 70)
    print(f"âœ“ Epochs: {config['epochs']}")
    print(f"âœ“ Final train loss: {train_losses[-1]:.6f}")
    print(f"âœ“ Final test loss: {test_losses[-1]:.6f}")
    print(f"âœ“ Best test loss: {best_loss:.6f}")
    if config['use_crop']:
        print(f"âœ“ Training mode: Cropped ({config['crop_mode']})")
    else:
        print(f"âœ“ Training mode: Full")
    print("=" * 70)
    print("ğŸ‰ Training completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
