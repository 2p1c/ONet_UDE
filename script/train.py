"""
DeepONetè®­ç»ƒè„šæœ¬ - ç²¾ç®€ç‰ˆ

æ•°æ®æµç¨‹: 5Ã—5Ã—50ä¿¡å· â†’ DeepONet â†’ 10Ã—10æŸä¼¤å›¾
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
import json  # æ–°å¢å¯¼å…¥

from data.dataset_simple import SimpleUSDataset3D
from nn.deeponet import DeepONet
from utils.data_utils import prepare_dataloaders
from utils.train_utils import train_model
from utils.visualization import plot_loss_curves, visualize_prediction


def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    print("=" * 70)
    print("DeepONet Training - Simplified")
    print("=" * 70)
    
    # ==================== é…ç½®å‚æ•° ====================
    config = {
        # æ•°æ®å‚æ•°
        'n_samples': 2000,  # ã€æ”¹è¿›4ã€‘ä» 1000 å¢åŠ åˆ° 2000
        'train_ratio': 0.8,
        # ã€å…³é”®ä¿®å¤ã€‘ç½‘ç»œå‚æ•° - branch_dim å¿…é¡»ä¸æ•°æ®é›†æ—¶é—´æ­¥é•¿ä¸€è‡´
        'nx': 5,
        'ny': 5,
        'sig_len': 100,
        'branch_dim': 5 * 5 * 100,
        'trunk_dim': 2,
        'branch_depth': 2,
        'trunk_depth': 3,
        'width': 100,  # ã€æ”¹è¿›7ã€‘ä» 50 å¢åŠ åˆ° 100
        'dropout': 0.15,  # ã€æ”¹è¿›3ã€‘æ·»åŠ  Dropout
        # è®­ç»ƒå‚æ•°
        'batch_size': 128,  # ã€æ”¹è¿›5ã€‘ä» 64 å¢åŠ åˆ° 128
        'epochs': 100,
        'lr': 5e-4,  # ã€æ”¹è¿›1ã€‘ä» 1e-3 é™åˆ° 5e-4
        # ã€æ–°å¢ã€‘æ­£åˆ™åŒ–å‚æ•°
        'weight_decay': 1e-4,
        # ã€æ–°å¢ã€‘æ—©åœå‚æ•°
        'early_stopping': True,
        'patience': 20,  # ã€ä¼˜åŒ–ã€‘ä» 15 å¢åŠ åˆ° 20
        # ã€æ–°å¢ã€‘å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
        'use_scheduler': True,
        'scheduler_patience': 5,  # ã€æ”¹è¿›2ã€‘ä» 10 æ”¹ä¸º 5
        'scheduler_factor': 0.5,
    }
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nâœ“ Device: {device}")
    print(f"âœ“ Training config:")
    print(f"  - Samples: {config['n_samples']}")
    print(f"  - Spatial grid: {config['nx']}Ã—{config['ny']}")
    print(f"  - Time steps: {config['sig_len']}")
    print(f"  - Branch dim: {config['branch_dim']}")  # æ–°å¢æ˜¾ç¤º
    print(f"  - Batch size: {config['batch_size']}")
    print(f"  - Learning rate: {config['lr']}")
    print(f"  - Weight decay: {config['weight_decay']}")
    print(f"  - Early stopping: patience={config['patience']}")
    
    # ==================== åŠ è½½æ•°æ® ====================
    print("\n" + "=" * 70)
    print("Loading Dataset...")
    print("=" * 70)
    
    # ã€ä¿®å¤ã€‘ä½¿ç”¨é…ç½®ä¸­çš„å‚æ•°åˆ›å»ºæ•°æ®é›†
    raw_dataset = SimpleUSDataset3D(
        n_samples=config['n_samples'],
        nx=config['nx'],
        ny=config['ny'],
        sig_len=config['sig_len'],  # ä½¿ç”¨é…ç½®ä¸­çš„æ—¶é—´æ­¥é•¿
        img_size=10,
        precompute=True
    )
    
    print(f"âœ“ Dataset loaded: {len(raw_dataset)} samples")
    print(f"  - Signal shape: ({config['ny']}, {config['nx']}, {config['sig_len']})")
    
    # ==================== å‡†å¤‡æ•°æ®åŠ è½½å™¨ ====================
    train_loader, test_loader, train_indices, test_indices = prepare_dataloaders(
        raw_dataset,
        train_ratio=config['train_ratio'],
        batch_size=config['batch_size']
    )
    
    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    print("\n" + "=" * 70)
    print("Initializing Model...")
    print("=" * 70)
    
    model = DeepONet(
        branch_dim=config['branch_dim'],
        trunk_dim=config['trunk_dim'],
        branch_depth=config['branch_depth'],
        trunk_depth=config['trunk_depth'],
        width=config['width'],
        activation='relu',
        initializer='Glorot normal',
        dropout=config.get('dropout', 0.0)  # ã€æ–°å¢ã€‘ä¼ å…¥ Dropout
    ).to(device)
    
    criterion = nn.MSELoss()
    
    # ã€ä¿®æ”¹ã€‘æ·»åŠ æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']  # L2æ­£åˆ™åŒ–
    )
    
    n_params = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Model initialized: {n_params:,} parameters")
    
    # ==================== è®­ç»ƒ ====================
    print("\n" + "=" * 70)
    print("Training...")
    print("=" * 70)
    
    os.makedirs('checkpoints', exist_ok=True)
    
    # ã€ä¿®æ”¹ã€‘ä¼ å…¥æ–°å‚æ•°
    train_losses, test_losses, best_loss = train_model(
        model, train_loader, test_loader,
        criterion, optimizer, device,
        epochs=config['epochs'],
        save_path='checkpoints/best_model.pth',
        # ã€æ–°å¢ã€‘æ—©åœå’Œå­¦ä¹ ç‡è°ƒåº¦
        early_stopping=config['early_stopping'],
        patience=config['patience'],
        use_scheduler=config['use_scheduler'],
        scheduler_patience=config['scheduler_patience'],
        scheduler_factor=config['scheduler_factor']
    )
    
    # ã€æ–°å¢ã€‘ä¿å­˜è®­ç»ƒé…ç½®å’ŒæŒ‡æ ‡
    print("\nSaving training configuration and metrics...")
    
    # ä¿å­˜é…ç½®
    config_save_path = 'checkpoints/last_config.json'
    with open(config_save_path, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"âœ“ Config saved to: {config_save_path}")
    
    # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
    metrics = {
        'train_losses': train_losses,
        'test_losses': test_losses,
        'best_test_loss': best_loss,
        'final_train_loss': train_losses[-1],
        'final_test_loss': test_losses[-1],
        'n_epochs_completed': len(train_losses),
    }
    metrics_save_path = 'checkpoints/last_metrics.pth'
    torch.save(metrics, metrics_save_path)
    print(f"âœ“ Metrics saved to: {metrics_save_path}")
    
    # ==================== å¯è§†åŒ– ====================
    print("\n" + "=" * 70)
    print("Generating Visualizations...")
    print("=" * 70)
    
    os.makedirs('images', exist_ok=True)
    
    # ç»˜åˆ¶æŸå¤±æ›²çº¿
    plot_loss_curves(train_losses, test_losses)
    
    # åŠ è½½æœ€ä½³æ¨¡å‹å¹¶é¢„æµ‹
    model.load_state_dict(torch.load('checkpoints/best_model.pth'))
    visualize_prediction(model, raw_dataset, test_indices[0], device)
    
    # ==================== æ€»ç»“ ====================
    print("\n" + "=" * 70)
    print("Training Summary")
    print("=" * 70)
    print(f"âœ“ Epochs: {config['epochs']}")
    print(f"âœ“ Final train loss: {train_losses[-1]:.6f}")
    print(f"âœ“ Final test loss: {test_losses[-1]:.6f}")
    print(f"âœ“ Best test loss: {best_loss:.6f}")
    print("=" * 70)
    print("ğŸ‰ Training completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
