"""
DeepONetè®­ç»ƒè„šæœ¬ - ç²¾ç®€ç‰ˆ

æ•°æ®æµç¨‹: 5Ã—5Ã—50ä¿¡å· â†’ DeepONet â†’ 10Ã—10æŸä¼¤å›¾

ã€æ–°å¢ã€‘æ”¯æŒè£å‰ªæ•°æ®é›†è®­ç»ƒï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
import json
import argparse
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import zoom

from data.dataset_simple import SimpleUSDataset3D
from data.transform import (
    create_cropped_dataset, 
    create_square_cropped_dataset, 
    create_damage_aware_dataset, 
    create_subgrid_dataset,  # ã€æ–°å¢ã€‘
    SquareCropper, 
    DamageAwareCropper
)
from nn.deeponet import DeepONet
from utils.data_utils import prepare_dataloaders
from utils.train_utils import train_model
from utils.visualization import (
    plot_loss_curves, 
    visualize_prediction,
    visualize_subgrid_training_flow  # ã€æ–°å¢ã€‘
)


def visualize_cropped_dataset_deeponet(raw_dataset, cropper, sample_idx=0, save_path='images/deeponet_cropped_data.png'):
    """
    å¯è§†åŒ–DeepONetä½¿ç”¨çš„è£å‰ªæ•°æ®é›†
    
    å±•ç¤ºå†…å®¹ï¼š
    1. åŸå§‹ 5Ã—5 ç©ºé—´åˆ†å¸ƒï¼ˆæŸæ—¶åˆ»ï¼‰
    2. è£å‰ªæ©ç ï¼ˆå“ªäº›ä¼ æ„Ÿå™¨è¢«ä¿ç•™ï¼‰
    3. è£å‰ªåä¿¡å·çš„æ—¶åŸŸæ³¢å½¢ï¼ˆflattenæˆä¸€ç»´ï¼‰
    4. ç›®æ ‡æŸä¼¤å›¾ï¼ˆä¸å˜ï¼‰
    
    Args:
        raw_dataset: åŸå§‹æ•°æ®é›†
        cropper: è£å‰ªå™¨ï¼ˆSquareCropper æˆ– DamageAwareCropperï¼‰
        sample_idx: æ ·æœ¬ç´¢å¼•
        save_path: ä¿å­˜è·¯å¾„
    """
    print(f"\nğŸ“Š Visualizing cropped dataset for DeepONet...")
    
    # è·å–åŸå§‹æ ·æœ¬
    sig_full, img_target = raw_dataset[sample_idx]  # (5, 5, 100), (10, 10)
    
    # ã€æ–°å¢ã€‘æ ¹æ®è£å‰ªå™¨ç±»å‹è°ƒç”¨ä¸åŒæ–¹æ³•
    if isinstance(cropper, DamageAwareCropper):
        # æŸä¼¤æ„ŸçŸ¥è£å‰ªéœ€è¦ä¼ å…¥æŸä¼¤å›¾
        sig_cropped, kept_indices, mask = cropper.crop_signal(
            sig_full,
            img_target,
            return_grid=False
        )
        # mask: (5, 5) äºŒå€¼çŸ©é˜µ
        crop_mode_name = 'damage_aware'
    elif isinstance(cropper, SquareCropper):
        # æ­£æ–¹å½¢è£å‰ª
        sig_cropped, kept_indices = cropper.crop_signal(sig_full, return_grid=False)
        mask = cropper.visualize_crop_pattern()
        crop_mode_name = cropper.crop_position
    else:
        raise TypeError(f"Unsupported cropper type: {type(cropper)}")
    
    # åˆ›å»ºå›¾å½¢
    fig = plt.figure(figsize=(20, 10))
    
    # ===== 1. åŸå§‹ 5Ã—5 ç©ºé—´åˆ†å¸ƒï¼ˆæŸæ—¶åˆ»ï¼‰=====
    ax1 = plt.subplot(2, 4, 1)
    time_idx = 20
    spatial_full = sig_full[:, :, time_idx]
    spatial_full_interp = zoom(spatial_full, 8, order=1)
    
    im1 = ax1.imshow(spatial_full_interp, cmap='seismic',
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal', vmin=-1, vmax=1)
    ax1.set_title('â‘  Full Signal (5Ã—5)\nat t=20Î¼s', fontsize=12, fontweight='bold')
    ax1.set_xlabel('x (mm)')
    ax1.set_ylabel('y (mm)')
    plt.colorbar(im1, ax=ax1, shrink=0.8)
    
    # æ ‡è®°æ‰€æœ‰ä¼ æ„Ÿå™¨
    x_pos = np.linspace(0, 100, 5)
    y_pos = np.linspace(0, 100, 5)
    xv, yv = np.meshgrid(x_pos, y_pos)
    ax1.plot(xv.flatten(), yv.flatten(), 'ko', markersize=8, alpha=0.6)
    
    # ===== 2. è£å‰ªæ©ç  =====
    ax2 = plt.subplot(2, 4, 2)
    im2 = ax2.imshow(mask, cmap='RdYlGn', vmin=0, vmax=1, origin='lower')
    ax2.set_title(f'â‘¡ Crop Mask\n({crop_mode_name} mode)', fontsize=12, fontweight='bold')
    
    for y in range(5):
        for x in range(5):
            if mask[y, x] == 1:
                ax2.plot(x, y, 'go', markersize=20)
                ax2.text(x, y, 'âœ“', ha='center', va='center',
                        color='white', fontweight='bold', fontsize=14)
            else:
                ax2.plot(x, y, 'rx', markersize=15, markeredgewidth=3)
                ax2.text(x, y, 'âœ—', ha='center', va='center',
                        color='darkred', fontweight='bold', fontsize=14)
    
    ax2.set_xticks(range(5))
    ax2.set_yticks(range(5))
    ax2.set_xlabel('x index')
    ax2.set_ylabel('y index')
    ax2.grid(True, alpha=0.3, linestyle='--')
    plt.colorbar(im2, ax=ax2, shrink=0.8, label='Kept (1) / Removed (0)')
    
    # ===== 3. è£å‰ªåç©ºé—´åˆ†å¸ƒ =====
    ax3 = plt.subplot(2, 4, 3)
    
    # ã€ä¿®æ”¹ã€‘æ ¹æ®è£å‰ªå™¨ç±»å‹é‡æ„ä¿¡å·
    if isinstance(cropper, DamageAwareCropper):
        # æŸä¼¤æ„ŸçŸ¥ï¼šç›´æ¥ä½¿ç”¨åŸå§‹5Ã—5ï¼Œè¢«ç§»é™¤ä½ç½®å·²ä¸º0
        spatial_cropped = sig_full[:, :, time_idx] * mask
        spatial_cropped_interp = zoom(spatial_cropped, 8, order=1)
        title_text = 'â‘¢ Cropped Signal (5Ã—5)\n(Removed = 0)'
    else:
        # æ­£æ–¹å½¢è£å‰ªï¼šé‡æ„åˆ°3Ã—3
        sig_cropped_grid = sig_cropped.reshape(3, 3, 100)
        spatial_cropped = sig_cropped_grid[:, :, time_idx]
        spatial_cropped_interp = zoom(spatial_cropped, 8, order=1)
        title_text = 'â‘¢ Cropped Signal (3Ã—3)\nat t=20Î¼s'
    
    im3 = ax3.imshow(spatial_cropped_interp, cmap='seismic',
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal', vmin=-1, vmax=1)
    ax3.set_title(title_text, fontsize=12, fontweight='bold')
    ax3.set_xlabel('x (mm)')
    ax3.set_ylabel('y (mm)')
    plt.colorbar(im3, ax=ax3, shrink=0.8)
    
    # æ ‡è®°ä¿ç•™çš„ä¼ æ„Ÿå™¨
    if isinstance(cropper, DamageAwareCropper):
        for y, x in kept_indices:
            x_mm = x * 25
            y_mm = y * 25
            ax3.plot(x_mm, y_mm, 'go', markersize=8)
    else:
        x_kept = np.linspace(0, 100, 3)
        y_kept = np.linspace(0, 100, 3)
        xv_kept, yv_kept = np.meshgrid(x_kept, y_kept)
        ax3.plot(xv_kept.flatten(), yv_kept.flatten(), 'go', markersize=8)
    
    # ===== 4. ç›®æ ‡æŸä¼¤å›¾ï¼ˆä¸å˜ï¼‰=====
    ax4 = plt.subplot(2, 4, 4)
    im4 = ax4.imshow(img_target, cmap='hot', vmin=0, vmax=1,
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal')
    ax4.set_title('â‘£ Target (10Ã—10)\n(Unchanged)', fontsize=12, fontweight='bold')
    ax4.set_xlabel('x (mm)')
    ax4.set_ylabel('y (mm)')
    plt.colorbar(im4, ax=ax4, shrink=0.8, label='Probability')
    
    # ===== 5. å®Œæ•´ä¿¡å·æ—¶åŸŸæ³¢å½¢ï¼ˆé€‰3ä¸ªç‚¹ï¼‰=====
    ax5 = plt.subplot(2, 4, 5)
    t_vec = np.linspace(0, 100, 100)
    
    # é€‰æ‹©3ä¸ªä¿ç•™ç‚¹çš„æ³¢å½¢
    for i in range(min(3, len(kept_indices))):
        y_idx, x_idx = kept_indices[i]
        sig_point = sig_full[y_idx, x_idx, :]
        ax5.plot(t_vec, sig_point, linewidth=1.2, 
                label=f'Kept point ({x_idx},{y_idx})', alpha=0.8)
    
    ax5.set_xlabel('Time (Î¼s)', fontsize=10)
    ax5.set_ylabel('Amplitude', fontsize=10)
    ax5.set_title('â‘¤ Time Signals (Kept Points)', fontsize=12, fontweight='bold')
    ax5.grid(True, alpha=0.3)
    ax5.legend(fontsize=9)
    ax5.axhline(0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)
    
    # ===== 6. è¢«ç§»é™¤ç‚¹çš„æ³¢å½¢ï¼ˆå¯¹æ¯”ï¼‰=====
    ax6 = plt.subplot(2, 4, 6)
    
    # æ‰¾å‡ºè¢«ç§»é™¤çš„ç‚¹
    all_points = [(y, x) for y in range(5) for x in range(5)]
    removed_indices = [pt for pt in all_points if pt not in kept_indices]
    
    for i in range(min(3, len(removed_indices))):
        y_idx, x_idx = removed_indices[i]
        sig_point = sig_full[y_idx, x_idx, :]
        ax6.plot(t_vec, sig_point, linewidth=1.2, linestyle='--',
                label=f'Removed ({x_idx},{y_idx})', alpha=0.7)
    
    ax6.set_xlabel('Time (Î¼s)', fontsize=10)
    ax6.set_ylabel('Amplitude', fontsize=10)
    ax6.set_title('â‘¥ Time Signals (Removed Points)', fontsize=12, fontweight='bold')
    ax6.grid(True, alpha=0.3)
    ax6.legend(fontsize=9)
    ax6.axhline(0, color='k', linewidth=0.5, linestyle='--', alpha=0.3)
    
    # ===== 7. DeepONetè¾“å…¥ç»´åº¦è¯´æ˜ =====
    ax7 = plt.subplot(2, 4, 7)
    ax7.axis('off')
    
    # ã€ä¿®æ”¹ã€‘æ ¹æ®è£å‰ªç±»å‹æ˜¾ç¤ºä¸åŒä¿¡æ¯
    n_kept = len(kept_indices)
    n_total = 25
    retention_rate = n_kept / n_total * 100
    
    if isinstance(cropper, DamageAwareCropper):
        text_info = f"""
    ğŸ“Š DeepONet Input (Damage-Aware)
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ”µ Original Signal:
       â€¢ Shape: (5, 5, 100)
       â€¢ Total: 2500 time samples
       â€¢ Branch input: 2500 dims
    
    âœ‚ï¸ After Cropping:
       â€¢ Shape: (5, 5, 100) â†’ flatten
       â€¢ Kept: {n_kept}/{n_total} sensors
       â€¢ Branch input: 2500 dims (0-padded)
    
    ğŸ“‰ Effective Retention:
       {retention_rate:.1f}% sensors active
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ¯ Target (Unchanged):
       â€¢ Shape: (10, 10)
       â€¢ Total: 100 output points
    
    ğŸ’¡ Key Insight:
       Damaged sensors removed!
       DeepONet must infer from
       partial observations.
    """
    else:
        text_info = f"""
    ğŸ“Š DeepONet Input Transformation
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ”µ Original Signal:
       â€¢ Shape: (5, 5, 100)
       â€¢ Total: 2500 time samples
       â€¢ Branch input: 2500 dims
    
    âœ‚ï¸ After Cropping:
       â€¢ Shape: (3, 3, 100) â†’ flatten
       â€¢ Total: 900 time samples
       â€¢ Branch input: 900 dims
    
    ğŸ“‰ Dimension Reduction:
       2500 â†’ 900 ({retention_rate:.1f}% retained)
    
    â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
    
    ğŸ¯ Target (Unchanged):
       â€¢ Shape: (10, 10)
       â€¢ Total: 100 output points
    
    ğŸ’¡ Key Insight:
       DeepONet must infer full damage
       from incomplete observations!
    """
    
    ax7.text(0.05, 0.5, text_info, fontsize=10, family='monospace',
            verticalalignment='center', transform=ax7.transAxes)
    
    # ===== 8. ä¿¡å·èƒ½é‡åˆ†å¸ƒå¯¹æ¯” =====
    ax8 = plt.subplot(2, 4, 8)
    
    # è®¡ç®—æ¯ä¸ªç‚¹çš„RMSèƒ½é‡
    rms_full = np.sqrt(np.mean(sig_full**2, axis=2))  # (5, 5)
    
    # ç»˜åˆ¶çƒ­åŠ›å›¾å¯¹æ¯”
    rms_full_interp = zoom(rms_full, 4, order=1)
    im8 = ax8.imshow(rms_full_interp, cmap='viridis',
                     extent=[0, 100, 0, 100],
                     origin='lower', aspect='equal')
    
    # ã€ä¿®æ”¹ã€‘æ ¹æ®è£å‰ªç±»å‹å åŠ ä¸åŒçš„æ ‡è®°
    if isinstance(cropper, DamageAwareCropper):
        # æ ‡è®°è¢«ç§»é™¤çš„ä¼ æ„Ÿå™¨
        for y, x in removed_indices:
            x_mm = x * 25
            y_mm = y * 25
            ax8.plot(x_mm, y_mm, 'rx', markersize=20, markeredgewidth=3)
        legend_text = 'Removed sensors'
    else:
        # å åŠ è£å‰ªåŒºåŸŸæ¡†ï¼ˆä¸­å¿ƒ3Ã—3ï¼‰
        rect_x = [20, 80, 80, 20, 20]
        rect_y = [20, 20, 80, 80, 20]
        ax8.plot(rect_x, rect_y, 'r-', linewidth=3)
        legend_text = 'Kept region'
    
    ax8.set_title('â‘§ RMS Energy Distribution\n(Full grid)', fontsize=12, fontweight='bold')
    ax8.set_xlabel('x (mm)')
    ax8.set_ylabel('y (mm)')
    plt.colorbar(im8, ax=ax8, shrink=0.8, label='RMS Energy')
    ax8.legend([legend_text], fontsize=9)
    
    plt.suptitle(f'DeepONet Cropped Dataset Visualization (Sample {sample_idx})\n'
                 f'Crop Mode: {crop_mode_name} | Kept: {n_kept}/{n_total} sensors ({retention_rate:.1f}%)',
                 fontsize=16, fontweight='bold', y=0.98)
    plt.tight_layout()
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ“ Visualization saved to {save_path}")
    plt.close()


def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    # ==================== è§£æå‘½ä»¤è¡Œå‚æ•° ====================
    parser = argparse.ArgumentParser(description='DeepONet Training')
    parser.add_argument(
        '--crop',
        action='store_true',
        help='ä½¿ç”¨è£å‰ªæ•°æ®é›†è®­ç»ƒ'
    )
    parser.add_argument(
        '--crop-mode',
        type=str,
        default='square',
        choices=['boundary', 'random', 'square', 'damage_aware'],  # ã€æ–°å¢ã€‘
        help='è£å‰ªæ¨¡å¼ï¼šboundary-è¾¹ç•Œç‚¹, random-éšæœºç‚¹, square-æ­£æ–¹å½¢è£å‰ª, damage_aware-åŸºäºæŸä¼¤è£å‰ª'
    )
    parser.add_argument(
        '--crop-position',
        type=str,
        default='center',
        choices=['center', 'corner', 'boundary', 'random'],
        help='squareæ¨¡å¼ä¸‹çš„è£å‰ªä½ç½®ï¼šcenter-ä¸­å¿ƒ3Ã—3, boundary-è¾¹ç•Œåˆ†æ•£'
    )
    parser.add_argument(
        '--n-keep',
        type=int,
        default=None,
        help='randomæ¨¡å¼ä¸‹ä¿ç•™çš„ä¼ æ„Ÿå™¨æ•°é‡'
    )
    parser.add_argument(
        '--damage-threshold',
        type=float,
        default=0.3,
        help='damage_awareæ¨¡å¼ä¸‹çš„æŸä¼¤é˜ˆå€¼'
    )
    parser.add_argument(
        '--min-keep',
        type=int,
        default=4,
        help='damage_awareæ¨¡å¼ä¸‹æœ€å°‘ä¿ç•™çš„ä¼ æ„Ÿå™¨æ•°'
    )
    parser.add_argument(
        '--use-subgrid',
        action='store_true',
        help='ä½¿ç”¨å­ç½‘æ ¼è®­ç»ƒæ¨¡å¼ï¼ˆ10Ã—10â†’5Ã—5ï¼‰'
    )
    parser.add_argument(
        '--img-size',
        type=int,
        default=10,
        help='æŸä¼¤å›¾å°ºå¯¸ï¼ˆ10æˆ–20ï¼‰'
    )
    parser.add_argument(
        '--defect-range-full',
        action='store_true',
        help='æŸä¼¤å¯å‡ºç°åœ¨æ•´ä¸ªåŒºåŸŸ[0,1]ï¼ˆé»˜è®¤[0.2,0.8]ï¼‰'
    )
    parser.add_argument(
        '--no-crop-input',
        action='store_true',
        help='ã€æ–°å¢ã€‘ä½¿ç”¨å®Œæ•´ä¼ æ„Ÿå™¨ç½‘æ ¼è¾“å…¥ï¼ˆä¸è£å‰ªè¾“å…¥ï¼Œåªè£å‰ªç›‘ç£ç›®æ ‡ï¼‰'
    )
    args = parser.parse_args()
    
    print("=" * 70)
    print("DeepONet Training - Simplified")
    if args.crop:
        print(f"ã€è£å‰ªæ¨¡å¼ã€‘Mode: {args.crop_mode}")
    print("=" * 70)
    
    # ==================== é…ç½®å‚æ•° ====================
    config = {
        # æ•°æ®å‚æ•°
        'n_samples': 2000,
        'train_ratio': 0.8,
        'nx': 5,
        'ny': 5,
        'sig_len': 100,
        # ã€å…³é”®ã€‘branch_dim å°†æ ¹æ®æ˜¯å¦è£å‰ªè‡ªåŠ¨è°ƒæ•´
        'branch_dim': None,  # ç¨åè®¾ç½®
        'trunk_dim': 2,
        'branch_depth': 2,
        'trunk_depth': 3,
        'width': 100,
        'dropout': 0.15,
        # è®­ç»ƒå‚æ•°
        'batch_size': 128,
        'epochs': 100,
        'lr': 5e-4,
        'weight_decay': 1e-4,
        # æ—©åœå‚æ•°
        'early_stopping': True,
        'patience': 20,
        # å­¦ä¹ ç‡è°ƒåº¦
        'use_scheduler': True,
        'scheduler_patience': 5,
        'scheduler_factor': 0.5,
        # ã€æ–°å¢ã€‘è£å‰ªå‚æ•°
        'use_crop': args.crop,
        'crop_mode': args.crop_mode,
        'n_keep': args.n_keep,
    }
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nâœ“ Device: {device}")
    
    # ==================== åŠ è½½æ•°æ® ====================
    print("\n" + "=" * 70)
    print("Loading Dataset...")
    print("=" * 70)
    
    # ã€ä¿®æ”¹ã€‘æ ¹æ®æ˜¯å¦ä½¿ç”¨å­ç½‘æ ¼ï¼Œè°ƒæ•´ç½‘æ ¼å°ºå¯¸
    grid_nx = 10 if args.use_subgrid else config['nx']
    grid_ny = 10 if args.use_subgrid else config['ny']
    
    # ã€ä¿®æ”¹ã€‘æ ¹æ®å‚æ•°è°ƒæ•´æŸä¼¤èŒƒå›´
    defect_range = (0.0, 1.0) if args.defect_range_full else (0.2, 0.8)
    
    # åˆ›å»ºåŸå§‹æ•°æ®é›†
    raw_dataset = SimpleUSDataset3D(
        n_samples=config['n_samples'],
        nx=grid_nx,
        ny=grid_ny,
        sig_len=config['sig_len'],
        img_size=args.img_size,  # ã€ä¿®æ”¹ã€‘æ”¯æŒ20Ã—20
        defect_range=defect_range,  # ã€æ–°å¢ã€‘
        precompute=True
    )
    
    print(f"âœ“ Base dataset loaded: {len(raw_dataset)} samples")
    print(f"  - Image size: {args.img_size}Ã—{args.img_size}")
    print(f"  - Defect range: {defect_range}")
    
    # ã€ä¿®æ”¹ã€‘å­ç½‘æ ¼æ¨¡å¼
    if args.use_subgrid:
        print(f"\nğŸ”ª Applying subgrid crop (10Ã—10 â†’ 5Ã—5)...")
        
        # ã€æ–°å¢ã€‘åˆ¤æ–­æ˜¯å¦è£å‰ªè¾“å…¥
        if args.no_crop_input:
            print(f"  âš ï¸  Input NOT cropped (using full 10Ã—10 signals)")
            print(f"  âœ“  Target cropped to center 10Ã—10 for supervision")
            
            # åˆ›å»ºç‰¹æ®Šçš„æ•°æ®é›†åŒ…è£…å™¨ï¼šä¸è£å‰ªè¾“å…¥ï¼Œåªè£å‰ªç›®æ ‡
            from data.transform import SubgridCropper
            
            cropper = SubgridCropper(
                full_nx=10,
                full_ny=10,
                sub_nx=10,  # ã€å…³é”®ã€‘ä¸è£å‰ªè¾“å…¥ï¼Œä¿æŒ10Ã—10
                sub_ny=10,
                sig_len=config['sig_len'],
                img_size=args.img_size,
                position='center',
                random_seed=42
            )
            
            # åˆ›å»ºæ•°æ®é›†ï¼šè¾“å…¥ä¸è£å‰ªï¼Œç›®æ ‡è£å‰ªåˆ°10Ã—10
            class FullInputSubgridDataset:
                """å®Œæ•´è¾“å…¥+è£å‰ªç›®æ ‡çš„æ•°æ®é›†"""
                def __init__(self, base_dataset, cropper, target_img_size=10):
                    self.base_dataset = base_dataset
                    self.cropper = cropper
                    self.target_img_size = target_img_size
                
                def __len__(self):
                    return len(self.base_dataset)
                
                def __getitem__(self, idx):
                    signal, image = self.base_dataset[idx]
                    # è¾“å…¥ï¼šå®Œæ•´10Ã—10ä¿¡å·ï¼ˆä¸è£å‰ªï¼‰
                    # ç›®æ ‡ï¼šè£å‰ªåˆ°ä¸­å¿ƒ10Ã—10
                    cropped_target = self.cropper.crop_image(image, target_size=self.target_img_size)
                    return signal, cropped_target
                
                def get_branch_dim(self):
                    # å®Œæ•´10Ã—10ä¿¡å·å±•å¹³
                    return 10 * 10 * self.cropper.sig_len
            
            dataset = FullInputSubgridDataset(raw_dataset, cropper, target_img_size=10)
            config['branch_dim'] = dataset.get_branch_dim()
            config['use_subgrid'] = True
            config['no_crop_input'] = True
            config['img_size'] = args.img_size
            config['train_img_size'] = 10
            
            print(f"âœ“ Full-input subgrid dataset created")
            print(f"  - Input: 10Ã—10 signals (10000 dims)")
            print(f"  - Training supervision: 10Ã—10 (center)")
            print(f"  - Full damage map: {args.img_size}Ã—{args.img_size}")
        else:
            # åŸæœ‰çš„è£å‰ªè¾“å…¥é€»è¾‘
            dataset, cropper = create_subgrid_dataset(
                raw_dataset,
                sub_nx=5,
                sub_ny=5,
                position='center',
                for_cnn=False,
                crop_target=True,
                target_img_size=10,
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
            config['use_subgrid'] = True
            config['no_crop_input'] = False  # ã€æ–°å¢ã€‘
            config['img_size'] = args.img_size
            config['train_img_size'] = 10
            print(f"âœ“ Subgrid dataset created")
            print(f"  - Training supervision: 10Ã—10 (center)")
            print(f"  - Full damage map: {args.img_size}Ã—{args.img_size}")
    elif config['use_crop']:
        print(f"\nğŸ”ª Applying crop transform...")
        
        if config['crop_mode'] == 'square':
            # ã€æ–°å¢ã€‘æ­£æ–¹å½¢è£å‰ªï¼ˆ3Ã—3ï¼‰
            dataset, cropper = create_square_cropped_dataset(
                raw_dataset,
                crop_size=3,
                crop_position=args.crop_position,
                for_cnn=False,  # DeepONetéœ€è¦flatten
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
            
            # ã€æ–°å¢ã€‘å¯è§†åŒ–è£å‰ªæ•°æ®é›†
            print("\nğŸ¨ Generating cropped dataset visualization...")
            visualize_cropped_dataset_deeponet(
                raw_dataset, 
                cropper, 
                sample_idx=0,
                save_path='images/deeponet_cropped_data_check.png'
            )
        elif config['crop_mode'] == 'damage_aware':
            # ã€æ–°å¢ã€‘åŸºäºæŸä¼¤çš„è£å‰ª
            dataset, cropper = create_damage_aware_dataset(
                raw_dataset,
                damage_threshold=args.damage_threshold,
                min_keep=args.min_keep,
                for_cnn=False,  # DeepONetéœ€è¦flatten
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
            config['damage_threshold'] = args.damage_threshold
            config['min_keep'] = args.min_keep
            
            # å¯è§†åŒ–æŸä¼¤æ˜ å°„
            print("\nğŸ¨ Generating damage mapping visualization...")
            sample_sig, sample_img = raw_dataset[0]
            cropper.visualize_damage_mapping(
                sample_img,
                save_path='images/dataset_check/damage_mapping.png'
            )
            print(f"âœ“ Damage-aware cropped dataset created")
        else:
            # åŸæœ‰çš„boundary/randomæ¨¡å¼
            dataset, cropper = create_cropped_dataset(
                raw_dataset,
                crop_mode=config['crop_mode'],
                n_keep=config['n_keep'],
                random_per_sample=True,
                random_seed=42
            )
            config['branch_dim'] = dataset.get_branch_dim()
    
    # ã€ä¿®å¤ã€‘æ— è£å‰ªå’Œå­ç½‘æ ¼æ—¶çš„å¤„ç†
    else:
        dataset = raw_dataset
        cropper = None
        config['branch_dim'] = config['nx'] * config['ny'] * config['sig_len']
        config['use_subgrid'] = False
        config['no_crop_input'] = False
        print(f"âœ“ Using full dataset (no crop)")
    
    print(f"\nâœ“ Training config:")
    print(f"  - Samples: {config['n_samples']}")
    print(f"  - Spatial grid: {config['nx']}Ã—{config['ny']}")
    print(f"  - Time steps: {config['sig_len']}")
    print(f"  - Branch dim: {config['branch_dim']}")
    if config['use_crop']:
        print(f"  - Crop mode: {config['crop_mode']}")
    print(f"  - Batch size: {config['batch_size']}")
    print(f"  - Learning rate: {config['lr']}")
    
    # ==================== å‡†å¤‡æ•°æ®åŠ è½½å™¨ ====================
    train_loader, test_loader, train_indices, test_indices = prepare_dataloaders(
        dataset,
        train_ratio=config['train_ratio'],
        batch_size=config['batch_size']
    )
    
    # ==================== åˆå§‹åŒ–æ¨¡å‹ ====================
    print("\n" + "=" * 70)
    print("Initializing Model...")
    print("=" * 70)
    
    model = DeepONet(
        branch_dim=config['branch_dim'],
        trunk_dim=config['trunk_dim'],
        branch_depth=config['branch_depth'],
        trunk_depth=config['trunk_depth'],
        width=config['width'],
        activation='relu',
        initializer='Glorot normal',
        dropout=config.get('dropout', 0.0)
    ).to(device)
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )
    
    n_params = sum(p.numel() for p in model.parameters())
    print(f"âœ“ Model initialized: {n_params:,} parameters")
    
    # ==================== è®­ç»ƒ ====================
    print("\n" + "=" * 70)
    print("Training...")
    print("=" * 70)
    
    os.makedirs('checkpoints', exist_ok=True)
    
    train_losses, test_losses, best_loss = train_model(
        model, train_loader, test_loader,
        criterion, optimizer, device,
        epochs=config['epochs'],
        save_path='checkpoints/best_model.pth',
        early_stopping=config['early_stopping'],
        patience=config['patience'],
        use_scheduler=config['use_scheduler'],
        scheduler_patience=config['scheduler_patience'],
        scheduler_factor=config['scheduler_factor']
    )
    
    # ==================== ä¿å­˜é…ç½®å’ŒæŒ‡æ ‡ ====================
    print("\nSaving training configuration and metrics...")
    
    config_save_path = 'checkpoints/last_config.json'
    with open(config_save_path, 'w') as f:
        json.dump(config, f, indent=2)
    print(f"âœ“ Config saved to: {config_save_path}")
    
    metrics = {
        'train_losses': train_losses,
        'test_losses': test_losses,
        'best_test_loss': best_loss,
        'final_train_loss': train_losses[-1],
        'final_test_loss': test_losses[-1],
        'n_epochs_completed': len(train_losses),
    }
    metrics_save_path = 'checkpoints/last_metrics.pth'
    torch.save(metrics, metrics_save_path)
    print(f"âœ“ Metrics saved to: {metrics_save_path}")
    
    # ==================== å¯è§†åŒ– ====================
    print("\n" + "=" * 70)
    print("Generating Visualizations...")
    print("=" * 70)
    
    os.makedirs('images', exist_ok=True)
    
    plot_loss_curves(train_losses, test_losses)
    
    # ã€ä¿®å¤ã€‘åŠ è½½æœ€ä½³æ¨¡å‹å¹¶é¢„æµ‹
    model.load_state_dict(torch.load('checkpoints/best_model.pth'))
    visualize_prediction(
        model, 
        raw_dataset, 
        test_indices[0], 
        device,
        cropper=cropper
    )
    
    # ã€æ–°å¢ã€‘å¦‚æœä½¿ç”¨å­ç½‘æ ¼æ¨¡å¼ï¼Œç”Ÿæˆç»¼åˆæµç¨‹å›¾
    if args.use_subgrid and args.img_size == 20:
        print("\nğŸ¨ Generating comprehensive subgrid training flow...")
        visualize_subgrid_training_flow(
            model,
            raw_dataset,
            cropper,
            sample_idx=test_indices[0],
            device=device,
            no_crop_input=config.get('no_crop_input', False),  # ã€æ–°å¢ã€‘ä¼ é€’æ ‡å¿—
            save_path='images/subgrid_training_flow.png'
        )
    
    # ã€æ–°å¢ã€‘å¦‚æœä½¿ç”¨äº†è£å‰ªï¼Œå†æ¬¡å¯è§†åŒ–è£å‰ªæ•°æ®é›†ï¼ˆä½¿ç”¨æµ‹è¯•æ ·æœ¬ï¼‰
    if config['use_crop'] and cropper is not None:
        os.makedirs('images/dataset_check', exist_ok=True)
        print("\nğŸ¨ Generating final cropped dataset visualization (test sample)...")
        visualize_cropped_dataset_deeponet(
            raw_dataset,
            cropper,
            sample_idx=test_indices[0],
            save_path='images/dataset_check/deeponet_cropped_test_sample.png'
        )
    
    # ==================== æ€»ç»“ ====================
    print("\n" + "=" * 70)
    print("Training Summary")
    print("=" * 70)
    print(f"âœ“ Epochs: {config['epochs']}")
    print(f"âœ“ Final train loss: {train_losses[-1]:.6f}")
    print(f"âœ“ Final test loss: {test_losses[-1]:.6f}")
    print(f"âœ“ Best test loss: {best_loss:.6f}")
    if config['use_crop']:
        print(f"âœ“ Training mode: Cropped ({config['crop_mode']})")
    else:
        print(f"âœ“ Training mode: Full")
    print("=" * 70)
    print("ğŸ‰ Training completed!")
    print("=" * 70)


if __name__ == "__main__":
    main()
